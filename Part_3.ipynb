{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRlf-VjoOZ8O"
   },
   "source": [
    "# Part 3 - Text analysis and ethics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tU8BnCXIOZ8T"
   },
   "source": [
    "# 3.a Computing PMI\n",
    "\n",
    "In this assessment you are tasked to discover strong associations between concepts in Airbnb reviews. The starter code we provide in this notebook is for orientation only. The below imports are enough to implement a valid answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_BJYvjpOZ8U"
   },
   "source": [
    "### Imports, data loading and helper functions\n",
    "\n",
    "We first connect our google drive, import pandas, numpy and some useful nltk and collections modules, then load the dataframe and define a function for printing the current time, useful to log our progress in some of the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "0z_s4GpwOZ8U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tag import pos_tag\n",
    "import re\n",
    "from collections import defaultdict,Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VFP8c6HlPF_-",
    "outputId": "0fa313c5-497c-44f6-f747-4d7ebf651661"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\Andreas\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\Andreas\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\Andreas\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# nltk imports, note that these outputs may be different if you are using colab or local jupyter notebooks\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "9JOWJqE9Pq5V"
   },
   "outputs": [],
   "source": [
    "# load stopwords\n",
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "LVD9Q3AxOZ8V"
   },
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "df = pd.read_csv(os.path.join(basedir,'reviews.csv'))\n",
    "# deal with empty reviews\n",
    "df.comments = df.comments.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "pNgPCqMPOZ8V",
    "outputId": "dd74578a-59c0-45c0-9228-3fefd61ac153"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   listing_id    id        date  reviewer_id reviewer_name  \\\n",
       "0        2818  1191  2009-03-30        10952           Lam   \n",
       "1        2818  1771  2009-04-24        12798         Alice   \n",
       "2        2818  1989  2009-05-03        11869       Natalja   \n",
       "3        2818  2797  2009-05-18        14064       Enrique   \n",
       "4        2818  3151  2009-05-25        17977       Sherwin   \n",
       "\n",
       "                                            comments  \n",
       "0  Daniel is really cool. The place was nice and ...  \n",
       "1  Daniel is the most amazing host! His place is ...  \n",
       "2  We had such a great time in Amsterdam. Daniel ...  \n",
       "3  Very professional operation. Room is very clea...  \n",
       "4  Daniel is highly recommended.  He provided all...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>listing_id</th>\n      <th>id</th>\n      <th>date</th>\n      <th>reviewer_id</th>\n      <th>reviewer_name</th>\n      <th>comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2818</td>\n      <td>1191</td>\n      <td>2009-03-30</td>\n      <td>10952</td>\n      <td>Lam</td>\n      <td>Daniel is really cool. The place was nice and ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2818</td>\n      <td>1771</td>\n      <td>2009-04-24</td>\n      <td>12798</td>\n      <td>Alice</td>\n      <td>Daniel is the most amazing host! His place is ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2818</td>\n      <td>1989</td>\n      <td>2009-05-03</td>\n      <td>11869</td>\n      <td>Natalja</td>\n      <td>We had such a great time in Amsterdam. Daniel ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2818</td>\n      <td>2797</td>\n      <td>2009-05-18</td>\n      <td>14064</td>\n      <td>Enrique</td>\n      <td>Very professional operation. Room is very clea...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2818</td>\n      <td>3151</td>\n      <td>2009-05-25</td>\n      <td>17977</td>\n      <td>Sherwin</td>\n      <td>Daniel is highly recommended.  He provided all...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_9leP4VOZ8W",
    "outputId": "010fcf4a-300c-4749-8cb8-04bed1fe68cb"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(452143, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJfVvyXyPYS4"
   },
   "source": [
    "### 3.a1 - Process reviews\n",
    "\n",
    "What to implement: A `function process_reviews(df)` that will take as input the original dataframe and will return it with three additional columns: `tokenized`, `tagged` and `lower_tagged`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "b7jF_XXsQYgK"
   },
   "outputs": [],
   "source": [
    "def process_reviews(df):\n",
    "  tokenized = []\n",
    "  tagged = []\n",
    "  lower_tagged = []\n",
    "\n",
    "  mylen = len(df)\n",
    "  count = 0\n",
    "  for index, row in df.iterrows():\n",
    "    token = word_tokenize(row.comments)\n",
    "    tokenized.append(token)\n",
    "    tagged.append(pos_tag(token))\n",
    "    lower_tagged.append(list(set(pos_tag([item.lower() for item in token]))))\n",
    "    count += 1\n",
    "    print(f'{count} out of {mylen}')\n",
    "    if count % 20000 == 0:      \n",
    "      break\n",
    "\n",
    "  df['tokenized'] = tokenized\n",
    "  df['tagged'] = tagged\n",
    "  df['lower_tagged'] = lower_tagged\n",
    "\n",
    "\n",
    "  # df['tokenized'] = [ word_tokenize(row.comments) for index, row in df.iterrows()]\n",
    "  # print('Tokenizing done!\\n')\n",
    "  # df['tagged'] = [pos_tag(row.tokenized) for index, row in df.iterrows()]\n",
    "  # print('Tagging done!\\n')\n",
    "  # df['lower_tagged'] = list(set([pos_tag([item.lower() for item in row.tokenized]) for index, row in df.iterrows()]))\n",
    "  # print('Lower tagging done!\\n')\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "rGYB8gx5Qq-P",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "t of 20000\n",
      "19005 out of 20000\n",
      "19006 out of 20000\n",
      "19007 out of 20000\n",
      "19008 out of 20000\n",
      "19009 out of 20000\n",
      "19010 out of 20000\n",
      "19011 out of 20000\n",
      "19012 out of 20000\n",
      "19013 out of 20000\n",
      "19014 out of 20000\n",
      "19015 out of 20000\n",
      "19016 out of 20000\n",
      "19017 out of 20000\n",
      "19018 out of 20000\n",
      "19019 out of 20000\n",
      "19020 out of 20000\n",
      "19021 out of 20000\n",
      "19022 out of 20000\n",
      "19023 out of 20000\n",
      "19024 out of 20000\n",
      "19025 out of 20000\n",
      "19026 out of 20000\n",
      "19027 out of 20000\n",
      "19028 out of 20000\n",
      "19029 out of 20000\n",
      "19030 out of 20000\n",
      "19031 out of 20000\n",
      "19032 out of 20000\n",
      "19033 out of 20000\n",
      "19034 out of 20000\n",
      "19035 out of 20000\n",
      "19036 out of 20000\n",
      "19037 out of 20000\n",
      "19038 out of 20000\n",
      "19039 out of 20000\n",
      "19040 out of 20000\n",
      "19041 out of 20000\n",
      "19042 out of 20000\n",
      "19043 out of 20000\n",
      "19044 out of 20000\n",
      "19045 out of 20000\n",
      "19046 out of 20000\n",
      "19047 out of 20000\n",
      "19048 out of 20000\n",
      "19049 out of 20000\n",
      "19050 out of 20000\n",
      "19051 out of 20000\n",
      "19052 out of 20000\n",
      "19053 out of 20000\n",
      "19054 out of 20000\n",
      "19055 out of 20000\n",
      "19056 out of 20000\n",
      "19057 out of 20000\n",
      "19058 out of 20000\n",
      "19059 out of 20000\n",
      "19060 out of 20000\n",
      "19061 out of 20000\n",
      "19062 out of 20000\n",
      "19063 out of 20000\n",
      "19064 out of 20000\n",
      "19065 out of 20000\n",
      "19066 out of 20000\n",
      "19067 out of 20000\n",
      "19068 out of 20000\n",
      "19069 out of 20000\n",
      "19070 out of 20000\n",
      "19071 out of 20000\n",
      "19072 out of 20000\n",
      "19073 out of 20000\n",
      "19074 out of 20000\n",
      "19075 out of 20000\n",
      "19076 out of 20000\n",
      "19077 out of 20000\n",
      "19078 out of 20000\n",
      "19079 out of 20000\n",
      "19080 out of 20000\n",
      "19081 out of 20000\n",
      "19082 out of 20000\n",
      "19083 out of 20000\n",
      "19084 out of 20000\n",
      "19085 out of 20000\n",
      "19086 out of 20000\n",
      "19087 out of 20000\n",
      "19088 out of 20000\n",
      "19089 out of 20000\n",
      "19090 out of 20000\n",
      "19091 out of 20000\n",
      "19092 out of 20000\n",
      "19093 out of 20000\n",
      "19094 out of 20000\n",
      "19095 out of 20000\n",
      "19096 out of 20000\n",
      "19097 out of 20000\n",
      "19098 out of 20000\n",
      "19099 out of 20000\n",
      "19100 out of 20000\n",
      "19101 out of 20000\n",
      "19102 out of 20000\n",
      "19103 out of 20000\n",
      "19104 out of 20000\n",
      "19105 out of 20000\n",
      "19106 out of 20000\n",
      "19107 out of 20000\n",
      "19108 out of 20000\n",
      "19109 out of 20000\n",
      "19110 out of 20000\n",
      "19111 out of 20000\n",
      "19112 out of 20000\n",
      "19113 out of 20000\n",
      "19114 out of 20000\n",
      "19115 out of 20000\n",
      "19116 out of 20000\n",
      "19117 out of 20000\n",
      "19118 out of 20000\n",
      "19119 out of 20000\n",
      "19120 out of 20000\n",
      "19121 out of 20000\n",
      "19122 out of 20000\n",
      "19123 out of 20000\n",
      "19124 out of 20000\n",
      "19125 out of 20000\n",
      "19126 out of 20000\n",
      "19127 out of 20000\n",
      "19128 out of 20000\n",
      "19129 out of 20000\n",
      "19130 out of 20000\n",
      "19131 out of 20000\n",
      "19132 out of 20000\n",
      "19133 out of 20000\n",
      "19134 out of 20000\n",
      "19135 out of 20000\n",
      "19136 out of 20000\n",
      "19137 out of 20000\n",
      "19138 out of 20000\n",
      "19139 out of 20000\n",
      "19140 out of 20000\n",
      "19141 out of 20000\n",
      "19142 out of 20000\n",
      "19143 out of 20000\n",
      "19144 out of 20000\n",
      "19145 out of 20000\n",
      "19146 out of 20000\n",
      "19147 out of 20000\n",
      "19148 out of 20000\n",
      "19149 out of 20000\n",
      "19150 out of 20000\n",
      "19151 out of 20000\n",
      "19152 out of 20000\n",
      "19153 out of 20000\n",
      "19154 out of 20000\n",
      "19155 out of 20000\n",
      "19156 out of 20000\n",
      "19157 out of 20000\n",
      "19158 out of 20000\n",
      "19159 out of 20000\n",
      "19160 out of 20000\n",
      "19161 out of 20000\n",
      "19162 out of 20000\n",
      "19163 out of 20000\n",
      "19164 out of 20000\n",
      "19165 out of 20000\n",
      "19166 out of 20000\n",
      "19167 out of 20000\n",
      "19168 out of 20000\n",
      "19169 out of 20000\n",
      "19170 out of 20000\n",
      "19171 out of 20000\n",
      "19172 out of 20000\n",
      "19173 out of 20000\n",
      "19174 out of 20000\n",
      "19175 out of 20000\n",
      "19176 out of 20000\n",
      "19177 out of 20000\n",
      "19178 out of 20000\n",
      "19179 out of 20000\n",
      "19180 out of 20000\n",
      "19181 out of 20000\n",
      "19182 out of 20000\n",
      "19183 out of 20000\n",
      "19184 out of 20000\n",
      "19185 out of 20000\n",
      "19186 out of 20000\n",
      "19187 out of 20000\n",
      "19188 out of 20000\n",
      "19189 out of 20000\n",
      "19190 out of 20000\n",
      "19191 out of 20000\n",
      "19192 out of 20000\n",
      "19193 out of 20000\n",
      "19194 out of 20000\n",
      "19195 out of 20000\n",
      "19196 out of 20000\n",
      "19197 out of 20000\n",
      "19198 out of 20000\n",
      "19199 out of 20000\n",
      "19200 out of 20000\n",
      "19201 out of 20000\n",
      "19202 out of 20000\n",
      "19203 out of 20000\n",
      "19204 out of 20000\n",
      "19205 out of 20000\n",
      "19206 out of 20000\n",
      "19207 out of 20000\n",
      "19208 out of 20000\n",
      "19209 out of 20000\n",
      "19210 out of 20000\n",
      "19211 out of 20000\n",
      "19212 out of 20000\n",
      "19213 out of 20000\n",
      "19214 out of 20000\n",
      "19215 out of 20000\n",
      "19216 out of 20000\n",
      "19217 out of 20000\n",
      "19218 out of 20000\n",
      "19219 out of 20000\n",
      "19220 out of 20000\n",
      "19221 out of 20000\n",
      "19222 out of 20000\n",
      "19223 out of 20000\n",
      "19224 out of 20000\n",
      "19225 out of 20000\n",
      "19226 out of 20000\n",
      "19227 out of 20000\n",
      "19228 out of 20000\n",
      "19229 out of 20000\n",
      "19230 out of 20000\n",
      "19231 out of 20000\n",
      "19232 out of 20000\n",
      "19233 out of 20000\n",
      "19234 out of 20000\n",
      "19235 out of 20000\n",
      "19236 out of 20000\n",
      "19237 out of 20000\n",
      "19238 out of 20000\n",
      "19239 out of 20000\n",
      "19240 out of 20000\n",
      "19241 out of 20000\n",
      "19242 out of 20000\n",
      "19243 out of 20000\n",
      "19244 out of 20000\n",
      "19245 out of 20000\n",
      "19246 out of 20000\n",
      "19247 out of 20000\n",
      "19248 out of 20000\n",
      "19249 out of 20000\n",
      "19250 out of 20000\n",
      "19251 out of 20000\n",
      "19252 out of 20000\n",
      "19253 out of 20000\n",
      "19254 out of 20000\n",
      "19255 out of 20000\n",
      "19256 out of 20000\n",
      "19257 out of 20000\n",
      "19258 out of 20000\n",
      "19259 out of 20000\n",
      "19260 out of 20000\n",
      "19261 out of 20000\n",
      "19262 out of 20000\n",
      "19263 out of 20000\n",
      "19264 out of 20000\n",
      "19265 out of 20000\n",
      "19266 out of 20000\n",
      "19267 out of 20000\n",
      "19268 out of 20000\n",
      "19269 out of 20000\n",
      "19270 out of 20000\n",
      "19271 out of 20000\n",
      "19272 out of 20000\n",
      "19273 out of 20000\n",
      "19274 out of 20000\n",
      "19275 out of 20000\n",
      "19276 out of 20000\n",
      "19277 out of 20000\n",
      "19278 out of 20000\n",
      "19279 out of 20000\n",
      "19280 out of 20000\n",
      "19281 out of 20000\n",
      "19282 out of 20000\n",
      "19283 out of 20000\n",
      "19284 out of 20000\n",
      "19285 out of 20000\n",
      "19286 out of 20000\n",
      "19287 out of 20000\n",
      "19288 out of 20000\n",
      "19289 out of 20000\n",
      "19290 out of 20000\n",
      "19291 out of 20000\n",
      "19292 out of 20000\n",
      "19293 out of 20000\n",
      "19294 out of 20000\n",
      "19295 out of 20000\n",
      "19296 out of 20000\n",
      "19297 out of 20000\n",
      "19298 out of 20000\n",
      "19299 out of 20000\n",
      "19300 out of 20000\n",
      "19301 out of 20000\n",
      "19302 out of 20000\n",
      "19303 out of 20000\n",
      "19304 out of 20000\n",
      "19305 out of 20000\n",
      "19306 out of 20000\n",
      "19307 out of 20000\n",
      "19308 out of 20000\n",
      "19309 out of 20000\n",
      "19310 out of 20000\n",
      "19311 out of 20000\n",
      "19312 out of 20000\n",
      "19313 out of 20000\n",
      "19314 out of 20000\n",
      "19315 out of 20000\n",
      "19316 out of 20000\n",
      "19317 out of 20000\n",
      "19318 out of 20000\n",
      "19319 out of 20000\n",
      "19320 out of 20000\n",
      "19321 out of 20000\n",
      "19322 out of 20000\n",
      "19323 out of 20000\n",
      "19324 out of 20000\n",
      "19325 out of 20000\n",
      "19326 out of 20000\n",
      "19327 out of 20000\n",
      "19328 out of 20000\n",
      "19329 out of 20000\n",
      "19330 out of 20000\n",
      "19331 out of 20000\n",
      "19332 out of 20000\n",
      "19333 out of 20000\n",
      "19334 out of 20000\n",
      "19335 out of 20000\n",
      "19336 out of 20000\n",
      "19337 out of 20000\n",
      "19338 out of 20000\n",
      "19339 out of 20000\n",
      "19340 out of 20000\n",
      "19341 out of 20000\n",
      "19342 out of 20000\n",
      "19343 out of 20000\n",
      "19344 out of 20000\n",
      "19345 out of 20000\n",
      "19346 out of 20000\n",
      "19347 out of 20000\n",
      "19348 out of 20000\n",
      "19349 out of 20000\n",
      "19350 out of 20000\n",
      "19351 out of 20000\n",
      "19352 out of 20000\n",
      "19353 out of 20000\n",
      "19354 out of 20000\n",
      "19355 out of 20000\n",
      "19356 out of 20000\n",
      "19357 out of 20000\n",
      "19358 out of 20000\n",
      "19359 out of 20000\n",
      "19360 out of 20000\n",
      "19361 out of 20000\n",
      "19362 out of 20000\n",
      "19363 out of 20000\n",
      "19364 out of 20000\n",
      "19365 out of 20000\n",
      "19366 out of 20000\n",
      "19367 out of 20000\n",
      "19368 out of 20000\n",
      "19369 out of 20000\n",
      "19370 out of 20000\n",
      "19371 out of 20000\n",
      "19372 out of 20000\n",
      "19373 out of 20000\n",
      "19374 out of 20000\n",
      "19375 out of 20000\n",
      "19376 out of 20000\n",
      "19377 out of 20000\n",
      "19378 out of 20000\n",
      "19379 out of 20000\n",
      "19380 out of 20000\n",
      "19381 out of 20000\n",
      "19382 out of 20000\n",
      "19383 out of 20000\n",
      "19384 out of 20000\n",
      "19385 out of 20000\n",
      "19386 out of 20000\n",
      "19387 out of 20000\n",
      "19388 out of 20000\n",
      "19389 out of 20000\n",
      "19390 out of 20000\n",
      "19391 out of 20000\n",
      "19392 out of 20000\n",
      "19393 out of 20000\n",
      "19394 out of 20000\n",
      "19395 out of 20000\n",
      "19396 out of 20000\n",
      "19397 out of 20000\n",
      "19398 out of 20000\n",
      "19399 out of 20000\n",
      "19400 out of 20000\n",
      "19401 out of 20000\n",
      "19402 out of 20000\n",
      "19403 out of 20000\n",
      "19404 out of 20000\n",
      "19405 out of 20000\n",
      "19406 out of 20000\n",
      "19407 out of 20000\n",
      "19408 out of 20000\n",
      "19409 out of 20000\n",
      "19410 out of 20000\n",
      "19411 out of 20000\n",
      "19412 out of 20000\n",
      "19413 out of 20000\n",
      "19414 out of 20000\n",
      "19415 out of 20000\n",
      "19416 out of 20000\n",
      "19417 out of 20000\n",
      "19418 out of 20000\n",
      "19419 out of 20000\n",
      "19420 out of 20000\n",
      "19421 out of 20000\n",
      "19422 out of 20000\n",
      "19423 out of 20000\n",
      "19424 out of 20000\n",
      "19425 out of 20000\n",
      "19426 out of 20000\n",
      "19427 out of 20000\n",
      "19428 out of 20000\n",
      "19429 out of 20000\n",
      "19430 out of 20000\n",
      "19431 out of 20000\n",
      "19432 out of 20000\n",
      "19433 out of 20000\n",
      "19434 out of 20000\n",
      "19435 out of 20000\n",
      "19436 out of 20000\n",
      "19437 out of 20000\n",
      "19438 out of 20000\n",
      "19439 out of 20000\n",
      "19440 out of 20000\n",
      "19441 out of 20000\n",
      "19442 out of 20000\n",
      "19443 out of 20000\n",
      "19444 out of 20000\n",
      "19445 out of 20000\n",
      "19446 out of 20000\n",
      "19447 out of 20000\n",
      "19448 out of 20000\n",
      "19449 out of 20000\n",
      "19450 out of 20000\n",
      "19451 out of 20000\n",
      "19452 out of 20000\n",
      "19453 out of 20000\n",
      "19454 out of 20000\n",
      "19455 out of 20000\n",
      "19456 out of 20000\n",
      "19457 out of 20000\n",
      "19458 out of 20000\n",
      "19459 out of 20000\n",
      "19460 out of 20000\n",
      "19461 out of 20000\n",
      "19462 out of 20000\n",
      "19463 out of 20000\n",
      "19464 out of 20000\n",
      "19465 out of 20000\n",
      "19466 out of 20000\n",
      "19467 out of 20000\n",
      "19468 out of 20000\n",
      "19469 out of 20000\n",
      "19470 out of 20000\n",
      "19471 out of 20000\n",
      "19472 out of 20000\n",
      "19473 out of 20000\n",
      "19474 out of 20000\n",
      "19475 out of 20000\n",
      "19476 out of 20000\n",
      "19477 out of 20000\n",
      "19478 out of 20000\n",
      "19479 out of 20000\n",
      "19480 out of 20000\n",
      "19481 out of 20000\n",
      "19482 out of 20000\n",
      "19483 out of 20000\n",
      "19484 out of 20000\n",
      "19485 out of 20000\n",
      "19486 out of 20000\n",
      "19487 out of 20000\n",
      "19488 out of 20000\n",
      "19489 out of 20000\n",
      "19490 out of 20000\n",
      "19491 out of 20000\n",
      "19492 out of 20000\n",
      "19493 out of 20000\n",
      "19494 out of 20000\n",
      "19495 out of 20000\n",
      "19496 out of 20000\n",
      "19497 out of 20000\n",
      "19498 out of 20000\n",
      "19499 out of 20000\n",
      "19500 out of 20000\n",
      "19501 out of 20000\n",
      "19502 out of 20000\n",
      "19503 out of 20000\n",
      "19504 out of 20000\n",
      "19505 out of 20000\n",
      "19506 out of 20000\n",
      "19507 out of 20000\n",
      "19508 out of 20000\n",
      "19509 out of 20000\n",
      "19510 out of 20000\n",
      "19511 out of 20000\n",
      "19512 out of 20000\n",
      "19513 out of 20000\n",
      "19514 out of 20000\n",
      "19515 out of 20000\n",
      "19516 out of 20000\n",
      "19517 out of 20000\n",
      "19518 out of 20000\n",
      "19519 out of 20000\n",
      "19520 out of 20000\n",
      "19521 out of 20000\n",
      "19522 out of 20000\n",
      "19523 out of 20000\n",
      "19524 out of 20000\n",
      "19525 out of 20000\n",
      "19526 out of 20000\n",
      "19527 out of 20000\n",
      "19528 out of 20000\n",
      "19529 out of 20000\n",
      "19530 out of 20000\n",
      "19531 out of 20000\n",
      "19532 out of 20000\n",
      "19533 out of 20000\n",
      "19534 out of 20000\n",
      "19535 out of 20000\n",
      "19536 out of 20000\n",
      "19537 out of 20000\n",
      "19538 out of 20000\n",
      "19539 out of 20000\n",
      "19540 out of 20000\n",
      "19541 out of 20000\n",
      "19542 out of 20000\n",
      "19543 out of 20000\n",
      "19544 out of 20000\n",
      "19545 out of 20000\n",
      "19546 out of 20000\n",
      "19547 out of 20000\n",
      "19548 out of 20000\n",
      "19549 out of 20000\n",
      "19550 out of 20000\n",
      "19551 out of 20000\n",
      "19552 out of 20000\n",
      "19553 out of 20000\n",
      "19554 out of 20000\n",
      "19555 out of 20000\n",
      "19556 out of 20000\n",
      "19557 out of 20000\n",
      "19558 out of 20000\n",
      "19559 out of 20000\n",
      "19560 out of 20000\n",
      "19561 out of 20000\n",
      "19562 out of 20000\n",
      "19563 out of 20000\n",
      "19564 out of 20000\n",
      "19565 out of 20000\n",
      "19566 out of 20000\n",
      "19567 out of 20000\n",
      "19568 out of 20000\n",
      "19569 out of 20000\n",
      "19570 out of 20000\n",
      "19571 out of 20000\n",
      "19572 out of 20000\n",
      "19573 out of 20000\n",
      "19574 out of 20000\n",
      "19575 out of 20000\n",
      "19576 out of 20000\n",
      "19577 out of 20000\n",
      "19578 out of 20000\n",
      "19579 out of 20000\n",
      "19580 out of 20000\n",
      "19581 out of 20000\n",
      "19582 out of 20000\n",
      "19583 out of 20000\n",
      "19584 out of 20000\n",
      "19585 out of 20000\n",
      "19586 out of 20000\n",
      "19587 out of 20000\n",
      "19588 out of 20000\n",
      "19589 out of 20000\n",
      "19590 out of 20000\n",
      "19591 out of 20000\n",
      "19592 out of 20000\n",
      "19593 out of 20000\n",
      "19594 out of 20000\n",
      "19595 out of 20000\n",
      "19596 out of 20000\n",
      "19597 out of 20000\n",
      "19598 out of 20000\n",
      "19599 out of 20000\n",
      "19600 out of 20000\n",
      "19601 out of 20000\n",
      "19602 out of 20000\n",
      "19603 out of 20000\n",
      "19604 out of 20000\n",
      "19605 out of 20000\n",
      "19606 out of 20000\n",
      "19607 out of 20000\n",
      "19608 out of 20000\n",
      "19609 out of 20000\n",
      "19610 out of 20000\n",
      "19611 out of 20000\n",
      "19612 out of 20000\n",
      "19613 out of 20000\n",
      "19614 out of 20000\n",
      "19615 out of 20000\n",
      "19616 out of 20000\n",
      "19617 out of 20000\n",
      "19618 out of 20000\n",
      "19619 out of 20000\n",
      "19620 out of 20000\n",
      "19621 out of 20000\n",
      "19622 out of 20000\n",
      "19623 out of 20000\n",
      "19624 out of 20000\n",
      "19625 out of 20000\n",
      "19626 out of 20000\n",
      "19627 out of 20000\n",
      "19628 out of 20000\n",
      "19629 out of 20000\n",
      "19630 out of 20000\n",
      "19631 out of 20000\n",
      "19632 out of 20000\n",
      "19633 out of 20000\n",
      "19634 out of 20000\n",
      "19635 out of 20000\n",
      "19636 out of 20000\n",
      "19637 out of 20000\n",
      "19638 out of 20000\n",
      "19639 out of 20000\n",
      "19640 out of 20000\n",
      "19641 out of 20000\n",
      "19642 out of 20000\n",
      "19643 out of 20000\n",
      "19644 out of 20000\n",
      "19645 out of 20000\n",
      "19646 out of 20000\n",
      "19647 out of 20000\n",
      "19648 out of 20000\n",
      "19649 out of 20000\n",
      "19650 out of 20000\n",
      "19651 out of 20000\n",
      "19652 out of 20000\n",
      "19653 out of 20000\n",
      "19654 out of 20000\n",
      "19655 out of 20000\n",
      "19656 out of 20000\n",
      "19657 out of 20000\n",
      "19658 out of 20000\n",
      "19659 out of 20000\n",
      "19660 out of 20000\n",
      "19661 out of 20000\n",
      "19662 out of 20000\n",
      "19663 out of 20000\n",
      "19664 out of 20000\n",
      "19665 out of 20000\n",
      "19666 out of 20000\n",
      "19667 out of 20000\n",
      "19668 out of 20000\n",
      "19669 out of 20000\n",
      "19670 out of 20000\n",
      "19671 out of 20000\n",
      "19672 out of 20000\n",
      "19673 out of 20000\n",
      "19674 out of 20000\n",
      "19675 out of 20000\n",
      "19676 out of 20000\n",
      "19677 out of 20000\n",
      "19678 out of 20000\n",
      "19679 out of 20000\n",
      "19680 out of 20000\n",
      "19681 out of 20000\n",
      "19682 out of 20000\n",
      "19683 out of 20000\n",
      "19684 out of 20000\n",
      "19685 out of 20000\n",
      "19686 out of 20000\n",
      "19687 out of 20000\n",
      "19688 out of 20000\n",
      "19689 out of 20000\n",
      "19690 out of 20000\n",
      "19691 out of 20000\n",
      "19692 out of 20000\n",
      "19693 out of 20000\n",
      "19694 out of 20000\n",
      "19695 out of 20000\n",
      "19696 out of 20000\n",
      "19697 out of 20000\n",
      "19698 out of 20000\n",
      "19699 out of 20000\n",
      "19700 out of 20000\n",
      "19701 out of 20000\n",
      "19702 out of 20000\n",
      "19703 out of 20000\n",
      "19704 out of 20000\n",
      "19705 out of 20000\n",
      "19706 out of 20000\n",
      "19707 out of 20000\n",
      "19708 out of 20000\n",
      "19709 out of 20000\n",
      "19710 out of 20000\n",
      "19711 out of 20000\n",
      "19712 out of 20000\n",
      "19713 out of 20000\n",
      "19714 out of 20000\n",
      "19715 out of 20000\n",
      "19716 out of 20000\n",
      "19717 out of 20000\n",
      "19718 out of 20000\n",
      "19719 out of 20000\n",
      "19720 out of 20000\n",
      "19721 out of 20000\n",
      "19722 out of 20000\n",
      "19723 out of 20000\n",
      "19724 out of 20000\n",
      "19725 out of 20000\n",
      "19726 out of 20000\n",
      "19727 out of 20000\n",
      "19728 out of 20000\n",
      "19729 out of 20000\n",
      "19730 out of 20000\n",
      "19731 out of 20000\n",
      "19732 out of 20000\n",
      "19733 out of 20000\n",
      "19734 out of 20000\n",
      "19735 out of 20000\n",
      "19736 out of 20000\n",
      "19737 out of 20000\n",
      "19738 out of 20000\n",
      "19739 out of 20000\n",
      "19740 out of 20000\n",
      "19741 out of 20000\n",
      "19742 out of 20000\n",
      "19743 out of 20000\n",
      "19744 out of 20000\n",
      "19745 out of 20000\n",
      "19746 out of 20000\n",
      "19747 out of 20000\n",
      "19748 out of 20000\n",
      "19749 out of 20000\n",
      "19750 out of 20000\n",
      "19751 out of 20000\n",
      "19752 out of 20000\n",
      "19753 out of 20000\n",
      "19754 out of 20000\n",
      "19755 out of 20000\n",
      "19756 out of 20000\n",
      "19757 out of 20000\n",
      "19758 out of 20000\n",
      "19759 out of 20000\n",
      "19760 out of 20000\n",
      "19761 out of 20000\n",
      "19762 out of 20000\n",
      "19763 out of 20000\n",
      "19764 out of 20000\n",
      "19765 out of 20000\n",
      "19766 out of 20000\n",
      "19767 out of 20000\n",
      "19768 out of 20000\n",
      "19769 out of 20000\n",
      "19770 out of 20000\n",
      "19771 out of 20000\n",
      "19772 out of 20000\n",
      "19773 out of 20000\n",
      "19774 out of 20000\n",
      "19775 out of 20000\n",
      "19776 out of 20000\n",
      "19777 out of 20000\n",
      "19778 out of 20000\n",
      "19779 out of 20000\n",
      "19780 out of 20000\n",
      "19781 out of 20000\n",
      "19782 out of 20000\n",
      "19783 out of 20000\n",
      "19784 out of 20000\n",
      "19785 out of 20000\n",
      "19786 out of 20000\n",
      "19787 out of 20000\n",
      "19788 out of 20000\n",
      "19789 out of 20000\n",
      "19790 out of 20000\n",
      "19791 out of 20000\n",
      "19792 out of 20000\n",
      "19793 out of 20000\n",
      "19794 out of 20000\n",
      "19795 out of 20000\n",
      "19796 out of 20000\n",
      "19797 out of 20000\n",
      "19798 out of 20000\n",
      "19799 out of 20000\n",
      "19800 out of 20000\n",
      "19801 out of 20000\n",
      "19802 out of 20000\n",
      "19803 out of 20000\n",
      "19804 out of 20000\n",
      "19805 out of 20000\n",
      "19806 out of 20000\n",
      "19807 out of 20000\n",
      "19808 out of 20000\n",
      "19809 out of 20000\n",
      "19810 out of 20000\n",
      "19811 out of 20000\n",
      "19812 out of 20000\n",
      "19813 out of 20000\n",
      "19814 out of 20000\n",
      "19815 out of 20000\n",
      "19816 out of 20000\n",
      "19817 out of 20000\n",
      "19818 out of 20000\n",
      "19819 out of 20000\n",
      "19820 out of 20000\n",
      "19821 out of 20000\n",
      "19822 out of 20000\n",
      "19823 out of 20000\n",
      "19824 out of 20000\n",
      "19825 out of 20000\n",
      "19826 out of 20000\n",
      "19827 out of 20000\n",
      "19828 out of 20000\n",
      "19829 out of 20000\n",
      "19830 out of 20000\n",
      "19831 out of 20000\n",
      "19832 out of 20000\n",
      "19833 out of 20000\n",
      "19834 out of 20000\n",
      "19835 out of 20000\n",
      "19836 out of 20000\n",
      "19837 out of 20000\n",
      "19838 out of 20000\n",
      "19839 out of 20000\n",
      "19840 out of 20000\n",
      "19841 out of 20000\n",
      "19842 out of 20000\n",
      "19843 out of 20000\n",
      "19844 out of 20000\n",
      "19845 out of 20000\n",
      "19846 out of 20000\n",
      "19847 out of 20000\n",
      "19848 out of 20000\n",
      "19849 out of 20000\n",
      "19850 out of 20000\n",
      "19851 out of 20000\n",
      "19852 out of 20000\n",
      "19853 out of 20000\n",
      "19854 out of 20000\n",
      "19855 out of 20000\n",
      "19856 out of 20000\n",
      "19857 out of 20000\n",
      "19858 out of 20000\n",
      "19859 out of 20000\n",
      "19860 out of 20000\n",
      "19861 out of 20000\n",
      "19862 out of 20000\n",
      "19863 out of 20000\n",
      "19864 out of 20000\n",
      "19865 out of 20000\n",
      "19866 out of 20000\n",
      "19867 out of 20000\n",
      "19868 out of 20000\n",
      "19869 out of 20000\n",
      "19870 out of 20000\n",
      "19871 out of 20000\n",
      "19872 out of 20000\n",
      "19873 out of 20000\n",
      "19874 out of 20000\n",
      "19875 out of 20000\n",
      "19876 out of 20000\n",
      "19877 out of 20000\n",
      "19878 out of 20000\n",
      "19879 out of 20000\n",
      "19880 out of 20000\n",
      "19881 out of 20000\n",
      "19882 out of 20000\n",
      "19883 out of 20000\n",
      "19884 out of 20000\n",
      "19885 out of 20000\n",
      "19886 out of 20000\n",
      "19887 out of 20000\n",
      "19888 out of 20000\n",
      "19889 out of 20000\n",
      "19890 out of 20000\n",
      "19891 out of 20000\n",
      "19892 out of 20000\n",
      "19893 out of 20000\n",
      "19894 out of 20000\n",
      "19895 out of 20000\n",
      "19896 out of 20000\n",
      "19897 out of 20000\n",
      "19898 out of 20000\n",
      "19899 out of 20000\n",
      "19900 out of 20000\n",
      "19901 out of 20000\n",
      "19902 out of 20000\n",
      "19903 out of 20000\n",
      "19904 out of 20000\n",
      "19905 out of 20000\n",
      "19906 out of 20000\n",
      "19907 out of 20000\n",
      "19908 out of 20000\n",
      "19909 out of 20000\n",
      "19910 out of 20000\n",
      "19911 out of 20000\n",
      "19912 out of 20000\n",
      "19913 out of 20000\n",
      "19914 out of 20000\n",
      "19915 out of 20000\n",
      "19916 out of 20000\n",
      "19917 out of 20000\n",
      "19918 out of 20000\n",
      "19919 out of 20000\n",
      "19920 out of 20000\n",
      "19921 out of 20000\n",
      "19922 out of 20000\n",
      "19923 out of 20000\n",
      "19924 out of 20000\n",
      "19925 out of 20000\n",
      "19926 out of 20000\n",
      "19927 out of 20000\n",
      "19928 out of 20000\n",
      "19929 out of 20000\n",
      "19930 out of 20000\n",
      "19931 out of 20000\n",
      "19932 out of 20000\n",
      "19933 out of 20000\n",
      "19934 out of 20000\n",
      "19935 out of 20000\n",
      "19936 out of 20000\n",
      "19937 out of 20000\n",
      "19938 out of 20000\n",
      "19939 out of 20000\n",
      "19940 out of 20000\n",
      "19941 out of 20000\n",
      "19942 out of 20000\n",
      "19943 out of 20000\n",
      "19944 out of 20000\n",
      "19945 out of 20000\n",
      "19946 out of 20000\n",
      "19947 out of 20000\n",
      "19948 out of 20000\n",
      "19949 out of 20000\n",
      "19950 out of 20000\n",
      "19951 out of 20000\n",
      "19952 out of 20000\n",
      "19953 out of 20000\n",
      "19954 out of 20000\n",
      "19955 out of 20000\n",
      "19956 out of 20000\n",
      "19957 out of 20000\n",
      "19958 out of 20000\n",
      "19959 out of 20000\n",
      "19960 out of 20000\n",
      "19961 out of 20000\n",
      "19962 out of 20000\n",
      "19963 out of 20000\n",
      "19964 out of 20000\n",
      "19965 out of 20000\n",
      "19966 out of 20000\n",
      "19967 out of 20000\n",
      "19968 out of 20000\n",
      "19969 out of 20000\n",
      "19970 out of 20000\n",
      "19971 out of 20000\n",
      "19972 out of 20000\n",
      "19973 out of 20000\n",
      "19974 out of 20000\n",
      "19975 out of 20000\n",
      "19976 out of 20000\n",
      "19977 out of 20000\n",
      "19978 out of 20000\n",
      "19979 out of 20000\n",
      "19980 out of 20000\n",
      "19981 out of 20000\n",
      "19982 out of 20000\n",
      "19983 out of 20000\n",
      "19984 out of 20000\n",
      "19985 out of 20000\n",
      "19986 out of 20000\n",
      "19987 out of 20000\n",
      "19988 out of 20000\n",
      "19989 out of 20000\n",
      "19990 out of 20000\n",
      "19991 out of 20000\n",
      "19992 out of 20000\n",
      "19993 out of 20000\n",
      "19994 out of 20000\n",
      "19995 out of 20000\n",
      "19996 out of 20000\n",
      "19997 out of 20000\n",
      "19998 out of 20000\n",
      "19999 out of 20000\n",
      "20000 out of 20000\n",
      "<ipython-input-134-c70933886d0c>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokenized'] = tokenized\n",
      "<ipython-input-134-c70933886d0c>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tagged'] = tagged\n",
      "<ipython-input-134-c70933886d0c>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lower_tagged'] = lower_tagged\n"
     ]
    }
   ],
   "source": [
    "df = process_reviews(df[:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       listing_id        id        date  reviewer_id reviewer_name  \\\n",
       "0            2818      1191  2009-03-30        10952           Lam   \n",
       "1            2818      1771  2009-04-24        12798         Alice   \n",
       "2            2818      1989  2009-05-03        11869       Natalja   \n",
       "3            2818      2797  2009-05-18        14064       Enrique   \n",
       "4            2818      3151  2009-05-25        17977       Sherwin   \n",
       "...           ...       ...         ...          ...           ...   \n",
       "19995      481664  51662420  2015-10-22     46551788        Martin   \n",
       "19996      481664  51885927  2015-10-25     37047887          Susi   \n",
       "19997      481664  52491199  2015-10-30      8500879      Kristine   \n",
       "19998      481664  53267155  2015-11-07     46466936     Alexander   \n",
       "19999      481664  55206755  2015-11-29     45639757         Vidya   \n",
       "\n",
       "                                                comments  \\\n",
       "0      Daniel is really cool. The place was nice and ...   \n",
       "1      Daniel is the most amazing host! His place is ...   \n",
       "2      We had such a great time in Amsterdam. Daniel ...   \n",
       "3      Very professional operation. Room is very clea...   \n",
       "4      Daniel is highly recommended.  He provided all...   \n",
       "...                                                  ...   \n",
       "19995  I had an amazing stay on Eltjo and Liselores b...   \n",
       "19996  Thank you so much for that wonderful stay. The...   \n",
       "19997  Eltjo and Liselore were very nice people and t...   \n",
       "19998  The hosts are friendly) all as on foto) далее ...   \n",
       "19999  Amazing experience! Eltjo and liselore were aw...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [Daniel, is, really, cool, ., The, place, was,...   \n",
       "1      [Daniel, is, the, most, amazing, host, !, His,...   \n",
       "2      [We, had, such, a, great, time, in, Amsterdam,...   \n",
       "3      [Very, professional, operation, ., Room, is, v...   \n",
       "4      [Daniel, is, highly, recommended, ., He, provi...   \n",
       "...                                                  ...   \n",
       "19995  [I, had, an, amazing, stay, on, Eltjo, and, Li...   \n",
       "19996  [Thank, you, so, much, for, that, wonderful, s...   \n",
       "19997  [Eltjo, and, Liselore, were, very, nice, peopl...   \n",
       "19998  [The, hosts, are, friendly, ), all, as, on, fo...   \n",
       "19999  [Amazing, experience, !, Eltjo, and, liselore,...   \n",
       "\n",
       "                                                  tagged  \\\n",
       "0      [(Daniel, NNP), (is, VBZ), (really, RB), (cool...   \n",
       "1      [(Daniel, NNP), (is, VBZ), (the, DT), (most, R...   \n",
       "2      [(We, PRP), (had, VBD), (such, JJ), (a, DT), (...   \n",
       "3      [(Very, RB), (professional, JJ), (operation, N...   \n",
       "4      [(Daniel, NNP), (is, VBZ), (highly, RB), (reco...   \n",
       "...                                                  ...   \n",
       "19995  [(I, PRP), (had, VBD), (an, DT), (amazing, JJ)...   \n",
       "19996  [(Thank, NNP), (you, PRP), (so, RB), (much, JJ...   \n",
       "19997  [(Eltjo, NNP), (and, CC), (Liselore, NNP), (we...   \n",
       "19998  [(The, DT), (hosts, NNS), (are, VBP), (friendl...   \n",
       "19999  [(Amazing, JJ), (experience, NN), (!, .), (Elt...   \n",
       "\n",
       "                                            lower_tagged  \n",
       "0      [(in, IN), (didnt, VBP), (any, DT), (clean, JJ...  \n",
       "1      [(please, VBP), (way, NN), (bed, NN), (if, IN)...  \n",
       "2      [(bathroom, NN), (10-15, JJ), (in, IN), (we, P...  \n",
       "3      [(which, WDT), (clean, JJ), (comfortable, JJ),...  \n",
       "4      [(way, NN), (in, IN), (which, WDT), (recommend...  \n",
       "...                                                  ...  \n",
       "19995  [(eltjo, NN), ('re, VBP), (if, IN), (exactly, ...  \n",
       "19996  [(thank, NN), (in, IN), (wonderful, JJ), (cosy...  \n",
       "19997  [(with, IN), (eltjo, NN), (water, NN), (thank,...  \n",
       "19998  [(и, JJ), (бы, NNP), (людишек, NNP), (переехал...  \n",
       "19999  [(with, IN), (eltjo, NN), (liselore, NN), (sta...  \n",
       "\n",
       "[20000 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>listing_id</th>\n      <th>id</th>\n      <th>date</th>\n      <th>reviewer_id</th>\n      <th>reviewer_name</th>\n      <th>comments</th>\n      <th>tokenized</th>\n      <th>tagged</th>\n      <th>lower_tagged</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2818</td>\n      <td>1191</td>\n      <td>2009-03-30</td>\n      <td>10952</td>\n      <td>Lam</td>\n      <td>Daniel is really cool. The place was nice and ...</td>\n      <td>[Daniel, is, really, cool, ., The, place, was,...</td>\n      <td>[(Daniel, NNP), (is, VBZ), (really, RB), (cool...</td>\n      <td>[(in, IN), (didnt, VBP), (any, DT), (clean, JJ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2818</td>\n      <td>1771</td>\n      <td>2009-04-24</td>\n      <td>12798</td>\n      <td>Alice</td>\n      <td>Daniel is the most amazing host! His place is ...</td>\n      <td>[Daniel, is, the, most, amazing, host, !, His,...</td>\n      <td>[(Daniel, NNP), (is, VBZ), (the, DT), (most, R...</td>\n      <td>[(please, VBP), (way, NN), (bed, NN), (if, IN)...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2818</td>\n      <td>1989</td>\n      <td>2009-05-03</td>\n      <td>11869</td>\n      <td>Natalja</td>\n      <td>We had such a great time in Amsterdam. Daniel ...</td>\n      <td>[We, had, such, a, great, time, in, Amsterdam,...</td>\n      <td>[(We, PRP), (had, VBD), (such, JJ), (a, DT), (...</td>\n      <td>[(bathroom, NN), (10-15, JJ), (in, IN), (we, P...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2818</td>\n      <td>2797</td>\n      <td>2009-05-18</td>\n      <td>14064</td>\n      <td>Enrique</td>\n      <td>Very professional operation. Room is very clea...</td>\n      <td>[Very, professional, operation, ., Room, is, v...</td>\n      <td>[(Very, RB), (professional, JJ), (operation, N...</td>\n      <td>[(which, WDT), (clean, JJ), (comfortable, JJ),...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2818</td>\n      <td>3151</td>\n      <td>2009-05-25</td>\n      <td>17977</td>\n      <td>Sherwin</td>\n      <td>Daniel is highly recommended.  He provided all...</td>\n      <td>[Daniel, is, highly, recommended, ., He, provi...</td>\n      <td>[(Daniel, NNP), (is, VBZ), (highly, RB), (reco...</td>\n      <td>[(way, NN), (in, IN), (which, WDT), (recommend...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>481664</td>\n      <td>51662420</td>\n      <td>2015-10-22</td>\n      <td>46551788</td>\n      <td>Martin</td>\n      <td>I had an amazing stay on Eltjo and Liselores b...</td>\n      <td>[I, had, an, amazing, stay, on, Eltjo, and, Li...</td>\n      <td>[(I, PRP), (had, VBD), (an, DT), (amazing, JJ)...</td>\n      <td>[(eltjo, NN), ('re, VBP), (if, IN), (exactly, ...</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>481664</td>\n      <td>51885927</td>\n      <td>2015-10-25</td>\n      <td>37047887</td>\n      <td>Susi</td>\n      <td>Thank you so much for that wonderful stay. The...</td>\n      <td>[Thank, you, so, much, for, that, wonderful, s...</td>\n      <td>[(Thank, NNP), (you, PRP), (so, RB), (much, JJ...</td>\n      <td>[(thank, NN), (in, IN), (wonderful, JJ), (cosy...</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>481664</td>\n      <td>52491199</td>\n      <td>2015-10-30</td>\n      <td>8500879</td>\n      <td>Kristine</td>\n      <td>Eltjo and Liselore were very nice people and t...</td>\n      <td>[Eltjo, and, Liselore, were, very, nice, peopl...</td>\n      <td>[(Eltjo, NNP), (and, CC), (Liselore, NNP), (we...</td>\n      <td>[(with, IN), (eltjo, NN), (water, NN), (thank,...</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>481664</td>\n      <td>53267155</td>\n      <td>2015-11-07</td>\n      <td>46466936</td>\n      <td>Alexander</td>\n      <td>The hosts are friendly) all as on foto) далее ...</td>\n      <td>[The, hosts, are, friendly, ), all, as, on, fo...</td>\n      <td>[(The, DT), (hosts, NNS), (are, VBP), (friendl...</td>\n      <td>[(и, JJ), (бы, NNP), (людишек, NNP), (переехал...</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>481664</td>\n      <td>55206755</td>\n      <td>2015-11-29</td>\n      <td>45639757</td>\n      <td>Vidya</td>\n      <td>Amazing experience! Eltjo and liselore were aw...</td>\n      <td>[Amazing, experience, !, Eltjo, and, liselore,...</td>\n      <td>[(Amazing, JJ), (experience, NN), (!, .), (Elt...</td>\n      <td>[(with, IN), (eltjo, NN), (liselore, NN), (sta...</td>\n    </tr>\n  </tbody>\n</table>\n<p>20000 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = 0\n",
    "# print(len(df.tagged[num]), len(set(df.lower_tagged[num])))\n",
    "# list(set(df.lower_tagged[num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'V'"
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "source": [
    "df.lower_tagged[0][1][1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUaH-yNlQRL9"
   },
   "source": [
    "### 3.a2 - Create a vocabulary\n",
    "\n",
    "What to implement: A function `get_vocab(df)` which takes as input the DataFrame generated in step 1.c, and returns two lists, one for the 1,000 most frequent center words (nouns) and one for the 1,000 most frequent context words (either verbs or adjectives). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "sAg6VRwdQQmg"
   },
   "outputs": [],
   "source": [
    "def get_vocab(df):\n",
    "  cent_list, cont_list = [], []\n",
    "\n",
    "  for review in df.lower_tagged:\n",
    "    cent_list.extend([word for word in [list_of_words[0] for list_of_words in review if list_of_words[1][0] == 'N']])\n",
    "    cont_list.extend([word for word in [list_of_words[0] for list_of_words in review if (list_of_words[1][0] == 'J') or (list_of_words[1][0] == 'V')]])\n",
    "    \n",
    "  cent_dict = Counter(cent_list)\n",
    "  cont_dict = Counter(cont_list)\n",
    "\n",
    "  cent_vocab = [key for key, value in sorted(cent_dict.items(), key=lambda item: item[1])][:1000]\n",
    "  cont_vocab = [key for key, value in sorted(cont_dict.items(), key=lambda item: item[1])][:1000]\n",
    "\n",
    "  return cent_vocab, cont_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "F_R5l4IVSk9-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cent_vocab, cont_vocab = get_vocab(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'compass'"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "cent_vocab[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkqRGdQ_RUMg"
   },
   "source": [
    "### 3.a3 Count co-occurrences between center and context words\n",
    "\n",
    "What to implement: A function `get_coocs(df, center_vocab, context_vocab)` which takes as input the DataFrame generated in step 1, and the lists generated in step 2 and returns a dictionary of dictionaries, of the form in the example above. It is up to you how you define context (full review? per sentence? a sliding window of fixed size?), and how to deal with exceptional cases (center words occurring more than once, center and context words being part of your vocabulary because they are frequent both as a noun and as a verb, etc). Use comments in your code to justify your approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "comments = df.comments\n",
    "type(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    Daniel is really cool. The place was nice and ...\n",
       "1    Daniel is the most amazing host! His place is ...\n",
       "2    We had such a great time in Amsterdam. Daniel ...\n",
       "3    Very professional operation. Room is very clea...\n",
       "4    Daniel is highly recommended.  He provided all...\n",
       "Name: comments, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "source": [
    "comments[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "ddnfCbQWRd5R"
   },
   "outputs": [],
   "source": [
    "def get_coocs(df, cent_vocab, cont_vocab):\n",
    "  sentences = []\n",
    "  comments = df.comments\n",
    "\n",
    "  for comment in comments:\n",
    "    sentences.extend([sentence for sentence in comment.split('.')])\n",
    "  \n",
    "  # print(sentences)\n",
    "  \n",
    "  coocs = {}\n",
    "\n",
    "  for center_word in cent_vocab:\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "      if center_word in sentence:\n",
    "        words_in_sentence = word_tokenize(sentence)\n",
    "        words.extend([word for word in words_in_sentence if word in cont_vocab])\n",
    "    \n",
    "    center_word_dict = dict(Counter(words))\n",
    "    coocs[center_word] = center_word_dict\n",
    "    \n",
    "  # cent_dict = Counter(cent_list)\n",
    "  # cont_dict = Counter(cont_list)\n",
    "  \n",
    "  return coocs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "iTT_TOkaSoXL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "coocs = get_coocs(df, cent_vocab, cont_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be6mOXqMRlt-"
   },
   "source": [
    "### 3.a4 Convert co-occurrence dictionary to 1000x1000 dataframe\n",
    "What to implement: A function called `cooc_dict2df(cooc_dict)`, which takes as input the dictionary of dictionaries generated in step 3 and returns a DataFrame where each row corresponds to one center word, and each column corresponds to one context word, and cells are their corresponding co-occurrence value. Some (x,y) pairs will never co-occur, you should have a 0 value for those cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "C6WuM5U7RsBJ"
   },
   "outputs": [],
   "source": [
    "def cooc_dict2df(coocs):\n",
    "  coocdf = pd.DataFrame(columns=cont_vocab, index = cent_vocab)\n",
    "\n",
    "  for index, row in coocdf.iterrows():\n",
    "    for word in cont_vocab:\n",
    "      try:\n",
    "        coocdf[word][index] = coocs[index][word]\n",
    "      except: \n",
    "        coocdf[word][index] = 0\n",
    "\n",
    "  return coocdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "cwAflxldSrbg"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "coocdf = cooc_dict2df(coocs)\n",
    "coocdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EWllWryR-QL"
   },
   "source": [
    "### 3.a5 Raw co-occurrences to PMI scores\n",
    "\n",
    "What to implement: A function `cooc2pmi(df)` that takes as input the DataFrame generated in step 4, and returns a new DataFrame with the same rows and columns, but with PMI scores instead of raw co-occurrence counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             umbrella convienient couldn.t bicycles exeptional unmatched  \\\n",
       "compass             1           0        0        0          0         0   \n",
       "travelguide         0           0        0        0          0         0   \n",
       "accomation          0           1        0        0          0         0   \n",
       "nuances             0           0        0        0          0         1   \n",
       "command             0           0        0        0          0         1   \n",
       "...               ...         ...      ...      ...        ...       ...   \n",
       "diversos            0           0        0        0          0         0   \n",
       "viajei              0           0        0        0          0         0   \n",
       "sozinha             0           0        0        0          0         0   \n",
       "leidsesplein        0           0        0        0          0         0   \n",
       "nachteil            0           0        0        0          0         0   \n",
       "\n",
       "             corny stucked asthetic well-thought-of  ... looooved familiarize  \\\n",
       "compass          0       0        0               0  ...        0           0   \n",
       "travelguide      0       0        0               0  ...        0           0   \n",
       "accomation       0       0        0               0  ...        0           0   \n",
       "nuances          0       0        0               0  ...        0           0   \n",
       "command          0       0        0               0  ...        0           0   \n",
       "...            ...     ...      ...             ...  ...      ...         ...   \n",
       "diversos         0       0        0               0  ...        0           0   \n",
       "viajei           0       0        0               0  ...        0           0   \n",
       "sozinha          0       0        0               0  ...        0           0   \n",
       "leidsesplein     0       0        0               0  ...        0           0   \n",
       "nachteil         0       0        0               0  ...        0           0   \n",
       "\n",
       "             awe-inspiring leidseplein/ worderful super-nice nearby-  \\\n",
       "compass                  0            0         0          0       0   \n",
       "travelguide              0            0         0          0       0   \n",
       "accomation               0            0         0          0       0   \n",
       "nuances                  0            0         0          0       0   \n",
       "command                  0            0         0          0       0   \n",
       "...                    ...          ...       ...        ...     ...   \n",
       "diversos                 0            0         0          0       0   \n",
       "viajei                   0            0         0          0       0   \n",
       "sozinha                  0            0         0          0       0   \n",
       "leidsesplein             0            0         0          0       0   \n",
       "nachteil                 0            0         0          0       0   \n",
       "\n",
       "             entertain +tram shore  \n",
       "compass              0     0     0  \n",
       "travelguide          0     0     0  \n",
       "accomation           0     0     0  \n",
       "nuances              0     0     0  \n",
       "command              0     0     0  \n",
       "...                ...   ...   ...  \n",
       "diversos             0     0     0  \n",
       "viajei               0     0     0  \n",
       "sozinha              0     0     0  \n",
       "leidsesplein         0     0     0  \n",
       "nachteil             0     0     0  \n",
       "\n",
       "[1000 rows x 1000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>umbrella</th>\n      <th>convienient</th>\n      <th>couldn.t</th>\n      <th>bicycles</th>\n      <th>exeptional</th>\n      <th>unmatched</th>\n      <th>corny</th>\n      <th>stucked</th>\n      <th>asthetic</th>\n      <th>well-thought-of</th>\n      <th>...</th>\n      <th>looooved</th>\n      <th>familiarize</th>\n      <th>awe-inspiring</th>\n      <th>leidseplein/</th>\n      <th>worderful</th>\n      <th>super-nice</th>\n      <th>nearby-</th>\n      <th>entertain</th>\n      <th>+tram</th>\n      <th>shore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>compass</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>travelguide</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>accomation</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>nuances</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>command</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>diversos</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>viajei</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>sozinha</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>leidsesplein</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>nachteil</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 1000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 190
    }
   ],
   "source": [
    "coocdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "frTTs7-eSFHv"
   },
   "outputs": [],
   "source": [
    "def cooc2pmi(df):\n",
    "  pmidf = pd.DataFrame(columns=cont_vocab, index = cent_vocab)\n",
    "\n",
    "  N = 0\n",
    "  for index, row in coocdf.iterrows():\n",
    "    N += sum(row)\n",
    "\n",
    "  for index, row in coocdf.iterrows():\n",
    "    for word in cont_vocab:\n",
    "      try:\n",
    "        pmi = df[index][word] / (sum(df[word])/N / sum(row)/N)\n",
    "        pmidf[word][index] = np.log2([pmi])[0] \n",
    "        print(pmidf[word][index])\n",
    "      except: \n",
    "        pmidf[word][index] = 0\n",
    "      \n",
    "  return pmidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "AGftXjXRSuQw"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23.847819078274203\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "<ipython-input-194-6d43e13bb03f>:12: RuntimeWarning: divide by zero encountered in log2\n",
      "  pmidf[word][index] = np.log2([pmi])[0]\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "25.43278157899536\n",
      "-inf\n",
      "24.43278157899536\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "23.847819078274203\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "20.625426656937755\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "23.695815984829153\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "22.847819078274203\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "22.847819078274203\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "23.43278157899536\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "22.847819078274203\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "-inf\n",
      "22.847819078274203\n",
      "-inf\n",
      "-inf\n",
      "-inf\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "metadata": {},
     "execution_count": 195
    }
   ],
   "source": [
    "pmidf = cooc2pmi(coocdf)\n",
    "pmidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             umbrella convienient couldn.t bicycles exeptional unmatched  \\\n",
       "compass             0           0        0        0          0         0   \n",
       "travelguide         0           0        0        0          0         0   \n",
       "accomation          0           0        0        0          0         0   \n",
       "nuances             0           0        0        0          0         0   \n",
       "command             0           0        0        0          0         0   \n",
       "...               ...         ...      ...      ...        ...       ...   \n",
       "diversos            0           0        0        0          0         0   \n",
       "viajei              0           0        0        0          0         0   \n",
       "sozinha             0           0        0        0          0         0   \n",
       "leidsesplein        0           0        0        0          0         0   \n",
       "nachteil            0           0        0        0          0         0   \n",
       "\n",
       "             corny stucked asthetic well-thought-of  ... looooved familiarize  \\\n",
       "compass          0       0        0               0  ...        0           0   \n",
       "travelguide      0       0        0               0  ...        0           0   \n",
       "accomation       0       0        0               0  ...        0           0   \n",
       "nuances          0       0        0               0  ...        0           0   \n",
       "command          0       0        0               0  ...        0           0   \n",
       "...            ...     ...      ...             ...  ...      ...         ...   \n",
       "diversos         0       0        0               0  ...        0           0   \n",
       "viajei           0       0        0               0  ...        0           0   \n",
       "sozinha          0       0        0               0  ...        0           0   \n",
       "leidsesplein     0       0        0               0  ...        0           0   \n",
       "nachteil         0       0        0               0  ...        0           0   \n",
       "\n",
       "             awe-inspiring leidseplein/ worderful super-nice nearby-  \\\n",
       "compass                  0            0         0          0       0   \n",
       "travelguide              0            0         0          0       0   \n",
       "accomation               0            0         0          0       0   \n",
       "nuances                  0            0         0          0       0   \n",
       "command                  0            0         0          0       0   \n",
       "...                    ...          ...       ...        ...     ...   \n",
       "diversos                 0            0         0          0       0   \n",
       "viajei                   0            0         0          0       0   \n",
       "sozinha                  0            0         0          0       0   \n",
       "leidsesplein             0            0         0          0       0   \n",
       "nachteil                 0            0         0          0       0   \n",
       "\n",
       "             entertain +tram shore  \n",
       "compass              0     0     0  \n",
       "travelguide          0     0     0  \n",
       "accomation           0     0     0  \n",
       "nuances              0     0     0  \n",
       "command              0     0     0  \n",
       "...                ...   ...   ...  \n",
       "diversos             0     0     0  \n",
       "viajei               0     0     0  \n",
       "sozinha              0     0     0  \n",
       "leidsesplein         0     0     0  \n",
       "nachteil             0     0     0  \n",
       "\n",
       "[1000 rows x 1000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>umbrella</th>\n      <th>convienient</th>\n      <th>couldn.t</th>\n      <th>bicycles</th>\n      <th>exeptional</th>\n      <th>unmatched</th>\n      <th>corny</th>\n      <th>stucked</th>\n      <th>asthetic</th>\n      <th>well-thought-of</th>\n      <th>...</th>\n      <th>looooved</th>\n      <th>familiarize</th>\n      <th>awe-inspiring</th>\n      <th>leidseplein/</th>\n      <th>worderful</th>\n      <th>super-nice</th>\n      <th>nearby-</th>\n      <th>entertain</th>\n      <th>+tram</th>\n      <th>shore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>compass</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>travelguide</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>accomation</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>nuances</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>command</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>diversos</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>viajei</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>sozinha</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>leidsesplein</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>nachteil</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 1000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 196
    }
   ],
   "source": [
    "pmidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "impatient    23.847819\n",
      "Name: impatient, dtype: object\n",
      "bountiful    24.432782\n",
      "Name: bountiful, dtype: object\n",
      "schlechte    22.847819\n",
      "Name: schlechte, dtype: object\n",
      "pensez    20.625427\n",
      "Name: pensez, dtype: object\n",
      "лучшее    23.847819\n",
      "Name: лучшее, dtype: object\n",
      "caracol    22.847819\n",
      "Name: caracol, dtype: object\n",
      "llegué    22.847819\n",
      "Name: llegué, dtype: object\n",
      "fiquei    22.847819\n",
      "Name: fiquei, dtype: object\n",
      "socialising    23.432782\n",
      "Name: socialising, dtype: object\n",
      "небольшие    23.695816\n",
      "Name: небольшие, dtype: object\n",
      "delen    25.432782\n",
      "Name: delen, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for name in cont_vocab:\n",
    "    if len(pmidf[name][pmidf[name] > 0]) > 0:\n",
    "        print(pmidf[name][pmidf[name] > 0 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaLRvjRySOYB"
   },
   "source": [
    "### 3.a6 Retrieve top-k context words, given a center word\n",
    "\n",
    "What to implement: A function `topk(df, center_word, N=10)` that takes as input: (1) the DataFrame generated in step 5, (2) a `center_word` (a string like `‘towels’`), and (3) an optional named argument called `N` with default value of 10; and returns a list of `N` strings, in order of their PMI score with the `center_word`. You do not need to handle cases for which the word `center_word` is not found in `df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "NlKUP9SgSXlL"
   },
   "outputs": [],
   "source": [
    "def topk(df, center_word, N=10):\n",
    "  top_words = sorted([df[word][center_word] for word in cont_vocab])[:N]\n",
    "  return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "1I038zG1Sw62"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "metadata": {},
     "execution_count": 207
    }
   ],
   "source": [
    "topk(pmidf, 'coffee')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hfcm5-7b0HKO"
   },
   "source": [
    "# 3.b Ethical, social and legal implications\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qd3uf-Qq4tYg"
   },
   "source": [
    "Local authorities in touristic hotspots like Amsterdam, NYC or Barcelona regulate the price of recreational apartments for rent to, among others, ensure that fair rent prices are kept for year-long residents. Consider your price recommender for hosts in Question 2c. Imagine that Airbnb recommends a new host to put the price of your flat at a price which is above the official regulations established by the local government. Upon inspection, you realize that the inflated price you have been recommended comes from many apartments in the area only being offered during an annual event which brings many tourists, and which causes prices to rise. \n",
    "\n",
    "In this context, critically reflect on the compliance of this recommender system with **one of the five actions** outlined in the **UK’s Data Ethics Framework**. You should prioritize the action that, in your opinion, is the weakest. Then, justify your choice by critically analyzing the three **key principles** outlined in the Framework, namely _transparency_, _accountability_ and _fairness_. Finally, you should propose and critically justify a solution that would improve the recommender system in at least one of these principles. You are strongly encouraged to follow a scholarly approach, e.g., with peer-reviewed references as support. \n",
    "\n",
    "Your report should be between 500 and 750 words long.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6QJyuP6I1Ht"
   },
   "source": [
    "### Your answer here. No Python, only Markdown.\n",
    "\n",
    "Write your answer after the line.\n",
    "\n",
    "---\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part 3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python395jvsc74a57bd03f75a622fdbe68ac4774c6ea619d86cc770141a8bef94a85fce2870eb7cb09bf",
   "display_name": "Python 3.9.5 64-bit ('Python39')"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "3f75a622fdbe68ac4774c6ea619d86cc770141a8bef94a85fce2870eb7cb09bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}