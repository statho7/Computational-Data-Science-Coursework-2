{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRlf-VjoOZ8O"
   },
   "source": [
    "# Part 3 - Text analysis and ethics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tU8BnCXIOZ8T"
   },
   "source": [
    "# 3.a Computing PMI\n",
    "\n",
    "In this assessment you are tasked to discover strong associations between concepts in Airbnb reviews. The starter code we provide in this notebook is for orientation only. The below imports are enough to implement a valid answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_BJYvjpOZ8U"
   },
   "source": [
    "### Imports, data loading and helper functions\n",
    "\n",
    "We first connect our google drive, import pandas, numpy and some useful nltk and collections modules, then load the dataframe and define a function for printing the current time, useful to log our progress in some of the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0z_s4GpwOZ8U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tag import pos_tag\n",
    "import re\n",
    "from collections import defaultdict,Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VFP8c6HlPF_-",
    "outputId": "0fa313c5-497c-44f6-f747-4d7ebf651661"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\Andreas\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\Andreas\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\Andreas\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# nltk imports, note that these outputs may be different if you are using colab or local jupyter notebooks\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9JOWJqE9Pq5V"
   },
   "outputs": [],
   "source": [
    "# load stopwords\n",
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LVD9Q3AxOZ8V"
   },
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "df = pd.read_csv(os.path.join(basedir,'reviews.csv'))\n",
    "# deal with empty reviews\n",
    "df.comments = df.comments.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "pNgPCqMPOZ8V",
    "outputId": "dd74578a-59c0-45c0-9228-3fefd61ac153"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   listing_id    id        date  reviewer_id reviewer_name  \\\n",
       "0        2818  1191  2009-03-30        10952           Lam   \n",
       "1        2818  1771  2009-04-24        12798         Alice   \n",
       "2        2818  1989  2009-05-03        11869       Natalja   \n",
       "3        2818  2797  2009-05-18        14064       Enrique   \n",
       "4        2818  3151  2009-05-25        17977       Sherwin   \n",
       "\n",
       "                                            comments  \n",
       "0  Daniel is really cool. The place was nice and ...  \n",
       "1  Daniel is the most amazing host! His place is ...  \n",
       "2  We had such a great time in Amsterdam. Daniel ...  \n",
       "3  Very professional operation. Room is very clea...  \n",
       "4  Daniel is highly recommended.  He provided all...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>listing_id</th>\n      <th>id</th>\n      <th>date</th>\n      <th>reviewer_id</th>\n      <th>reviewer_name</th>\n      <th>comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2818</td>\n      <td>1191</td>\n      <td>2009-03-30</td>\n      <td>10952</td>\n      <td>Lam</td>\n      <td>Daniel is really cool. The place was nice and ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2818</td>\n      <td>1771</td>\n      <td>2009-04-24</td>\n      <td>12798</td>\n      <td>Alice</td>\n      <td>Daniel is the most amazing host! His place is ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2818</td>\n      <td>1989</td>\n      <td>2009-05-03</td>\n      <td>11869</td>\n      <td>Natalja</td>\n      <td>We had such a great time in Amsterdam. Daniel ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2818</td>\n      <td>2797</td>\n      <td>2009-05-18</td>\n      <td>14064</td>\n      <td>Enrique</td>\n      <td>Very professional operation. Room is very clea...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2818</td>\n      <td>3151</td>\n      <td>2009-05-25</td>\n      <td>17977</td>\n      <td>Sherwin</td>\n      <td>Daniel is highly recommended.  He provided all...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_9leP4VOZ8W",
    "outputId": "010fcf4a-300c-4749-8cb8-04bed1fe68cb"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(452143, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJfVvyXyPYS4"
   },
   "source": [
    "### 3.a1 - Process reviews\n",
    "\n",
    "What to implement: A `function process_reviews(df)` that will take as input the original dataframe and will return it with three additional columns: `tokenized`, `tagged` and `lower_tagged`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "b7jF_XXsQYgK"
   },
   "outputs": [],
   "source": [
    "def process_reviews(df):\n",
    "  tokenized = []\n",
    "  tagged = []\n",
    "  lower_tagged = []\n",
    "\n",
    "  mylen = len(df)\n",
    "  count = 0\n",
    "  for index, row in df.iterrows():\n",
    "    token = word_tokenize(row.comments)\n",
    "    tokenized.append(token)\n",
    "    tagged.append(pos_tag(token))\n",
    "    lower_tagged.append(list(set(pos_tag([item.lower() for item in token]))))\n",
    "    count += 1\n",
    "    print(f'{count} out of {mylen}')\n",
    "    if count % 1000 == 0:      \n",
    "      break\n",
    "\n",
    "  df['tokenized'] = tokenized\n",
    "  df['tagged'] = tagged\n",
    "  df['lower_tagged'] = lower_tagged\n",
    "\n",
    "\n",
    "  # df['tokenized'] = [ word_tokenize(row.comments) for index, row in df.iterrows()]\n",
    "  # print('Tokenizing done!\\n')\n",
    "  # df['tagged'] = [pos_tag(row.tokenized) for index, row in df.iterrows()]\n",
    "  # print('Tagging done!\\n')\n",
    "  # df['lower_tagged'] = list(set([pos_tag([item.lower() for item in row.tokenized]) for index, row in df.iterrows()]))\n",
    "  # print('Lower tagging done!\\n')\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rGYB8gx5Qq-P"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 out of 1000\n",
      "2 out of 1000\n",
      "3 out of 1000\n",
      "4 out of 1000\n",
      "5 out of 1000\n",
      "6 out of 1000\n",
      "7 out of 1000\n",
      "8 out of 1000\n",
      "9 out of 1000\n",
      "10 out of 1000\n",
      "11 out of 1000\n",
      "12 out of 1000\n",
      "13 out of 1000\n",
      "14 out of 1000\n",
      "15 out of 1000\n",
      "16 out of 1000\n",
      "17 out of 1000\n",
      "18 out of 1000\n",
      "19 out of 1000\n",
      "20 out of 1000\n",
      "21 out of 1000\n",
      "22 out of 1000\n",
      "23 out of 1000\n",
      "24 out of 1000\n",
      "25 out of 1000\n",
      "26 out of 1000\n",
      "27 out of 1000\n",
      "28 out of 1000\n",
      "29 out of 1000\n",
      "30 out of 1000\n",
      "31 out of 1000\n",
      "32 out of 1000\n",
      "33 out of 1000\n",
      "34 out of 1000\n",
      "35 out of 1000\n",
      "36 out of 1000\n",
      "37 out of 1000\n",
      "38 out of 1000\n",
      "39 out of 1000\n",
      "40 out of 1000\n",
      "41 out of 1000\n",
      "42 out of 1000\n",
      "43 out of 1000\n",
      "44 out of 1000\n",
      "45 out of 1000\n",
      "46 out of 1000\n",
      "47 out of 1000\n",
      "48 out of 1000\n",
      "49 out of 1000\n",
      "50 out of 1000\n",
      "51 out of 1000\n",
      "52 out of 1000\n",
      "53 out of 1000\n",
      "54 out of 1000\n",
      "55 out of 1000\n",
      "56 out of 1000\n",
      "57 out of 1000\n",
      "58 out of 1000\n",
      "59 out of 1000\n",
      "60 out of 1000\n",
      "61 out of 1000\n",
      "62 out of 1000\n",
      "63 out of 1000\n",
      "64 out of 1000\n",
      "65 out of 1000\n",
      "66 out of 1000\n",
      "67 out of 1000\n",
      "68 out of 1000\n",
      "69 out of 1000\n",
      "70 out of 1000\n",
      "71 out of 1000\n",
      "72 out of 1000\n",
      "73 out of 1000\n",
      "74 out of 1000\n",
      "75 out of 1000\n",
      "76 out of 1000\n",
      "77 out of 1000\n",
      "78 out of 1000\n",
      "79 out of 1000\n",
      "80 out of 1000\n",
      "81 out of 1000\n",
      "82 out of 1000\n",
      "83 out of 1000\n",
      "84 out of 1000\n",
      "85 out of 1000\n",
      "86 out of 1000\n",
      "87 out of 1000\n",
      "88 out of 1000\n",
      "89 out of 1000\n",
      "90 out of 1000\n",
      "91 out of 1000\n",
      "92 out of 1000\n",
      "93 out of 1000\n",
      "94 out of 1000\n",
      "95 out of 1000\n",
      "96 out of 1000\n",
      "97 out of 1000\n",
      "98 out of 1000\n",
      "99 out of 1000\n",
      "100 out of 1000\n",
      "101 out of 1000\n",
      "102 out of 1000\n",
      "103 out of 1000\n",
      "104 out of 1000\n",
      "105 out of 1000\n",
      "106 out of 1000\n",
      "107 out of 1000\n",
      "108 out of 1000\n",
      "109 out of 1000\n",
      "110 out of 1000\n",
      "111 out of 1000\n",
      "112 out of 1000\n",
      "113 out of 1000\n",
      "114 out of 1000\n",
      "115 out of 1000\n",
      "116 out of 1000\n",
      "117 out of 1000\n",
      "118 out of 1000\n",
      "119 out of 1000\n",
      "120 out of 1000\n",
      "121 out of 1000\n",
      "122 out of 1000\n",
      "123 out of 1000\n",
      "124 out of 1000\n",
      "125 out of 1000\n",
      "126 out of 1000\n",
      "127 out of 1000\n",
      "128 out of 1000\n",
      "129 out of 1000\n",
      "130 out of 1000\n",
      "131 out of 1000\n",
      "132 out of 1000\n",
      "133 out of 1000\n",
      "134 out of 1000\n",
      "135 out of 1000\n",
      "136 out of 1000\n",
      "137 out of 1000\n",
      "138 out of 1000\n",
      "139 out of 1000\n",
      "140 out of 1000\n",
      "141 out of 1000\n",
      "142 out of 1000\n",
      "143 out of 1000\n",
      "144 out of 1000\n",
      "145 out of 1000\n",
      "146 out of 1000\n",
      "147 out of 1000\n",
      "148 out of 1000\n",
      "149 out of 1000\n",
      "150 out of 1000\n",
      "151 out of 1000\n",
      "152 out of 1000\n",
      "153 out of 1000\n",
      "154 out of 1000\n",
      "155 out of 1000\n",
      "156 out of 1000\n",
      "157 out of 1000\n",
      "158 out of 1000\n",
      "159 out of 1000\n",
      "160 out of 1000\n",
      "161 out of 1000\n",
      "162 out of 1000\n",
      "163 out of 1000\n",
      "164 out of 1000\n",
      "165 out of 1000\n",
      "166 out of 1000\n",
      "167 out of 1000\n",
      "168 out of 1000\n",
      "169 out of 1000\n",
      "170 out of 1000\n",
      "171 out of 1000\n",
      "172 out of 1000\n",
      "173 out of 1000\n",
      "174 out of 1000\n",
      "175 out of 1000\n",
      "176 out of 1000\n",
      "177 out of 1000\n",
      "178 out of 1000\n",
      "179 out of 1000\n",
      "180 out of 1000\n",
      "181 out of 1000\n",
      "182 out of 1000\n",
      "183 out of 1000\n",
      "184 out of 1000\n",
      "185 out of 1000\n",
      "186 out of 1000\n",
      "187 out of 1000\n",
      "188 out of 1000\n",
      "189 out of 1000\n",
      "190 out of 1000\n",
      "191 out of 1000\n",
      "192 out of 1000\n",
      "193 out of 1000\n",
      "194 out of 1000\n",
      "195 out of 1000\n",
      "196 out of 1000\n",
      "197 out of 1000\n",
      "198 out of 1000\n",
      "199 out of 1000\n",
      "200 out of 1000\n",
      "201 out of 1000\n",
      "202 out of 1000\n",
      "203 out of 1000\n",
      "204 out of 1000\n",
      "205 out of 1000\n",
      "206 out of 1000\n",
      "207 out of 1000\n",
      "208 out of 1000\n",
      "209 out of 1000\n",
      "210 out of 1000\n",
      "211 out of 1000\n",
      "212 out of 1000\n",
      "213 out of 1000\n",
      "214 out of 1000\n",
      "215 out of 1000\n",
      "216 out of 1000\n",
      "217 out of 1000\n",
      "218 out of 1000\n",
      "219 out of 1000\n",
      "220 out of 1000\n",
      "221 out of 1000\n",
      "222 out of 1000\n",
      "223 out of 1000\n",
      "224 out of 1000\n",
      "225 out of 1000\n",
      "226 out of 1000\n",
      "227 out of 1000\n",
      "228 out of 1000\n",
      "229 out of 1000\n",
      "230 out of 1000\n",
      "231 out of 1000\n",
      "232 out of 1000\n",
      "233 out of 1000\n",
      "234 out of 1000\n",
      "235 out of 1000\n",
      "236 out of 1000\n",
      "237 out of 1000\n",
      "238 out of 1000\n",
      "239 out of 1000\n",
      "240 out of 1000\n",
      "241 out of 1000\n",
      "242 out of 1000\n",
      "243 out of 1000\n",
      "244 out of 1000\n",
      "245 out of 1000\n",
      "246 out of 1000\n",
      "247 out of 1000\n",
      "248 out of 1000\n",
      "249 out of 1000\n",
      "250 out of 1000\n",
      "251 out of 1000\n",
      "252 out of 1000\n",
      "253 out of 1000\n",
      "254 out of 1000\n",
      "255 out of 1000\n",
      "256 out of 1000\n",
      "257 out of 1000\n",
      "258 out of 1000\n",
      "259 out of 1000\n",
      "260 out of 1000\n",
      "261 out of 1000\n",
      "262 out of 1000\n",
      "263 out of 1000\n",
      "264 out of 1000\n",
      "265 out of 1000\n",
      "266 out of 1000\n",
      "267 out of 1000\n",
      "268 out of 1000\n",
      "269 out of 1000\n",
      "270 out of 1000\n",
      "271 out of 1000\n",
      "272 out of 1000\n",
      "273 out of 1000\n",
      "274 out of 1000\n",
      "275 out of 1000\n",
      "276 out of 1000\n",
      "277 out of 1000\n",
      "278 out of 1000\n",
      "279 out of 1000\n",
      "280 out of 1000\n",
      "281 out of 1000\n",
      "282 out of 1000\n",
      "283 out of 1000\n",
      "284 out of 1000\n",
      "285 out of 1000\n",
      "286 out of 1000\n",
      "287 out of 1000\n",
      "288 out of 1000\n",
      "289 out of 1000\n",
      "290 out of 1000\n",
      "291 out of 1000\n",
      "292 out of 1000\n",
      "293 out of 1000\n",
      "294 out of 1000\n",
      "295 out of 1000\n",
      "296 out of 1000\n",
      "297 out of 1000\n",
      "298 out of 1000\n",
      "299 out of 1000\n",
      "300 out of 1000\n",
      "301 out of 1000\n",
      "302 out of 1000\n",
      "303 out of 1000\n",
      "304 out of 1000\n",
      "305 out of 1000\n",
      "306 out of 1000\n",
      "307 out of 1000\n",
      "308 out of 1000\n",
      "309 out of 1000\n",
      "310 out of 1000\n",
      "311 out of 1000\n",
      "312 out of 1000\n",
      "313 out of 1000\n",
      "314 out of 1000\n",
      "315 out of 1000\n",
      "316 out of 1000\n",
      "317 out of 1000\n",
      "318 out of 1000\n",
      "319 out of 1000\n",
      "320 out of 1000\n",
      "321 out of 1000\n",
      "322 out of 1000\n",
      "323 out of 1000\n",
      "324 out of 1000\n",
      "325 out of 1000\n",
      "326 out of 1000\n",
      "327 out of 1000\n",
      "328 out of 1000\n",
      "329 out of 1000\n",
      "330 out of 1000\n",
      "331 out of 1000\n",
      "332 out of 1000\n",
      "333 out of 1000\n",
      "334 out of 1000\n",
      "335 out of 1000\n",
      "336 out of 1000\n",
      "337 out of 1000\n",
      "338 out of 1000\n",
      "339 out of 1000\n",
      "340 out of 1000\n",
      "341 out of 1000\n",
      "342 out of 1000\n",
      "343 out of 1000\n",
      "344 out of 1000\n",
      "345 out of 1000\n",
      "346 out of 1000\n",
      "347 out of 1000\n",
      "348 out of 1000\n",
      "349 out of 1000\n",
      "350 out of 1000\n",
      "351 out of 1000\n",
      "352 out of 1000\n",
      "353 out of 1000\n",
      "354 out of 1000\n",
      "355 out of 1000\n",
      "356 out of 1000\n",
      "357 out of 1000\n",
      "358 out of 1000\n",
      "359 out of 1000\n",
      "360 out of 1000\n",
      "361 out of 1000\n",
      "362 out of 1000\n",
      "363 out of 1000\n",
      "364 out of 1000\n",
      "365 out of 1000\n",
      "366 out of 1000\n",
      "367 out of 1000\n",
      "368 out of 1000\n",
      "369 out of 1000\n",
      "370 out of 1000\n",
      "371 out of 1000\n",
      "372 out of 1000\n",
      "373 out of 1000\n",
      "374 out of 1000\n",
      "375 out of 1000\n",
      "376 out of 1000\n",
      "377 out of 1000\n",
      "378 out of 1000\n",
      "379 out of 1000\n",
      "380 out of 1000\n",
      "381 out of 1000\n",
      "382 out of 1000\n",
      "383 out of 1000\n",
      "384 out of 1000\n",
      "385 out of 1000\n",
      "386 out of 1000\n",
      "387 out of 1000\n",
      "388 out of 1000\n",
      "389 out of 1000\n",
      "390 out of 1000\n",
      "391 out of 1000\n",
      "392 out of 1000\n",
      "393 out of 1000\n",
      "394 out of 1000\n",
      "395 out of 1000\n",
      "396 out of 1000\n",
      "397 out of 1000\n",
      "398 out of 1000\n",
      "399 out of 1000\n",
      "400 out of 1000\n",
      "401 out of 1000\n",
      "402 out of 1000\n",
      "403 out of 1000\n",
      "404 out of 1000\n",
      "405 out of 1000\n",
      "406 out of 1000\n",
      "407 out of 1000\n",
      "408 out of 1000\n",
      "409 out of 1000\n",
      "410 out of 1000\n",
      "411 out of 1000\n",
      "412 out of 1000\n",
      "413 out of 1000\n",
      "414 out of 1000\n",
      "415 out of 1000\n",
      "416 out of 1000\n",
      "417 out of 1000\n",
      "418 out of 1000\n",
      "419 out of 1000\n",
      "420 out of 1000\n",
      "421 out of 1000\n",
      "422 out of 1000\n",
      "423 out of 1000\n",
      "424 out of 1000\n",
      "425 out of 1000\n",
      "426 out of 1000\n",
      "427 out of 1000\n",
      "428 out of 1000\n",
      "429 out of 1000\n",
      "430 out of 1000\n",
      "431 out of 1000\n",
      "432 out of 1000\n",
      "433 out of 1000\n",
      "434 out of 1000\n",
      "435 out of 1000\n",
      "436 out of 1000\n",
      "437 out of 1000\n",
      "438 out of 1000\n",
      "439 out of 1000\n",
      "440 out of 1000\n",
      "441 out of 1000\n",
      "442 out of 1000\n",
      "443 out of 1000\n",
      "444 out of 1000\n",
      "445 out of 1000\n",
      "446 out of 1000\n",
      "447 out of 1000\n",
      "448 out of 1000\n",
      "449 out of 1000\n",
      "450 out of 1000\n",
      "451 out of 1000\n",
      "452 out of 1000\n",
      "453 out of 1000\n",
      "454 out of 1000\n",
      "455 out of 1000\n",
      "456 out of 1000\n",
      "457 out of 1000\n",
      "458 out of 1000\n",
      "459 out of 1000\n",
      "460 out of 1000\n",
      "461 out of 1000\n",
      "462 out of 1000\n",
      "463 out of 1000\n",
      "464 out of 1000\n",
      "465 out of 1000\n",
      "466 out of 1000\n",
      "467 out of 1000\n",
      "468 out of 1000\n",
      "469 out of 1000\n",
      "470 out of 1000\n",
      "471 out of 1000\n",
      "472 out of 1000\n",
      "473 out of 1000\n",
      "474 out of 1000\n",
      "475 out of 1000\n",
      "476 out of 1000\n",
      "477 out of 1000\n",
      "478 out of 1000\n",
      "479 out of 1000\n",
      "480 out of 1000\n",
      "481 out of 1000\n",
      "482 out of 1000\n",
      "483 out of 1000\n",
      "484 out of 1000\n",
      "485 out of 1000\n",
      "486 out of 1000\n",
      "487 out of 1000\n",
      "488 out of 1000\n",
      "489 out of 1000\n",
      "490 out of 1000\n",
      "491 out of 1000\n",
      "492 out of 1000\n",
      "493 out of 1000\n",
      "494 out of 1000\n",
      "495 out of 1000\n",
      "496 out of 1000\n",
      "497 out of 1000\n",
      "498 out of 1000\n",
      "499 out of 1000\n",
      "500 out of 1000\n",
      "501 out of 1000\n",
      "502 out of 1000\n",
      "503 out of 1000\n",
      "504 out of 1000\n",
      "505 out of 1000\n",
      "506 out of 1000\n",
      "507 out of 1000\n",
      "508 out of 1000\n",
      "509 out of 1000\n",
      "510 out of 1000\n",
      "511 out of 1000\n",
      "512 out of 1000\n",
      "513 out of 1000\n",
      "514 out of 1000\n",
      "515 out of 1000\n",
      "516 out of 1000\n",
      "517 out of 1000\n",
      "518 out of 1000\n",
      "519 out of 1000\n",
      "520 out of 1000\n",
      "521 out of 1000\n",
      "522 out of 1000\n",
      "523 out of 1000\n",
      "524 out of 1000\n",
      "525 out of 1000\n",
      "526 out of 1000\n",
      "527 out of 1000\n",
      "528 out of 1000\n",
      "529 out of 1000\n",
      "530 out of 1000\n",
      "531 out of 1000\n",
      "532 out of 1000\n",
      "533 out of 1000\n",
      "534 out of 1000\n",
      "535 out of 1000\n",
      "536 out of 1000\n",
      "537 out of 1000\n",
      "538 out of 1000\n",
      "539 out of 1000\n",
      "540 out of 1000\n",
      "541 out of 1000\n",
      "542 out of 1000\n",
      "543 out of 1000\n",
      "544 out of 1000\n",
      "545 out of 1000\n",
      "546 out of 1000\n",
      "547 out of 1000\n",
      "548 out of 1000\n",
      "549 out of 1000\n",
      "550 out of 1000\n",
      "551 out of 1000\n",
      "552 out of 1000\n",
      "553 out of 1000\n",
      "554 out of 1000\n",
      "555 out of 1000\n",
      "556 out of 1000\n",
      "557 out of 1000\n",
      "558 out of 1000\n",
      "559 out of 1000\n",
      "560 out of 1000\n",
      "561 out of 1000\n",
      "562 out of 1000\n",
      "563 out of 1000\n",
      "564 out of 1000\n",
      "565 out of 1000\n",
      "566 out of 1000\n",
      "567 out of 1000\n",
      "568 out of 1000\n",
      "569 out of 1000\n",
      "570 out of 1000\n",
      "571 out of 1000\n",
      "572 out of 1000\n",
      "573 out of 1000\n",
      "574 out of 1000\n",
      "575 out of 1000\n",
      "576 out of 1000\n",
      "577 out of 1000\n",
      "578 out of 1000\n",
      "579 out of 1000\n",
      "580 out of 1000\n",
      "581 out of 1000\n",
      "582 out of 1000\n",
      "583 out of 1000\n",
      "584 out of 1000\n",
      "585 out of 1000\n",
      "586 out of 1000\n",
      "587 out of 1000\n",
      "588 out of 1000\n",
      "589 out of 1000\n",
      "590 out of 1000\n",
      "591 out of 1000\n",
      "592 out of 1000\n",
      "593 out of 1000\n",
      "594 out of 1000\n",
      "595 out of 1000\n",
      "596 out of 1000\n",
      "597 out of 1000\n",
      "598 out of 1000\n",
      "599 out of 1000\n",
      "600 out of 1000\n",
      "601 out of 1000\n",
      "602 out of 1000\n",
      "603 out of 1000\n",
      "604 out of 1000\n",
      "605 out of 1000\n",
      "606 out of 1000\n",
      "607 out of 1000\n",
      "608 out of 1000\n",
      "609 out of 1000\n",
      "610 out of 1000\n",
      "611 out of 1000\n",
      "612 out of 1000\n",
      "613 out of 1000\n",
      "614 out of 1000\n",
      "615 out of 1000\n",
      "616 out of 1000\n",
      "617 out of 1000\n",
      "618 out of 1000\n",
      "619 out of 1000\n",
      "620 out of 1000\n",
      "621 out of 1000\n",
      "622 out of 1000\n",
      "623 out of 1000\n",
      "624 out of 1000\n",
      "625 out of 1000\n",
      "626 out of 1000\n",
      "627 out of 1000\n",
      "628 out of 1000\n",
      "629 out of 1000\n",
      "630 out of 1000\n",
      "631 out of 1000\n",
      "632 out of 1000\n",
      "633 out of 1000\n",
      "634 out of 1000\n",
      "635 out of 1000\n",
      "636 out of 1000\n",
      "637 out of 1000\n",
      "638 out of 1000\n",
      "639 out of 1000\n",
      "640 out of 1000\n",
      "641 out of 1000\n",
      "642 out of 1000\n",
      "643 out of 1000\n",
      "644 out of 1000\n",
      "645 out of 1000\n",
      "646 out of 1000\n",
      "647 out of 1000\n",
      "648 out of 1000\n",
      "649 out of 1000\n",
      "650 out of 1000\n",
      "651 out of 1000\n",
      "652 out of 1000\n",
      "653 out of 1000\n",
      "654 out of 1000\n",
      "655 out of 1000\n",
      "656 out of 1000\n",
      "657 out of 1000\n",
      "658 out of 1000\n",
      "659 out of 1000\n",
      "660 out of 1000\n",
      "661 out of 1000\n",
      "662 out of 1000\n",
      "663 out of 1000\n",
      "664 out of 1000\n",
      "665 out of 1000\n",
      "666 out of 1000\n",
      "667 out of 1000\n",
      "668 out of 1000\n",
      "669 out of 1000\n",
      "670 out of 1000\n",
      "671 out of 1000\n",
      "672 out of 1000\n",
      "673 out of 1000\n",
      "674 out of 1000\n",
      "675 out of 1000\n",
      "676 out of 1000\n",
      "677 out of 1000\n",
      "678 out of 1000\n",
      "679 out of 1000\n",
      "680 out of 1000\n",
      "681 out of 1000\n",
      "682 out of 1000\n",
      "683 out of 1000\n",
      "684 out of 1000\n",
      "685 out of 1000\n",
      "686 out of 1000\n",
      "687 out of 1000\n",
      "688 out of 1000\n",
      "689 out of 1000\n",
      "690 out of 1000\n",
      "691 out of 1000\n",
      "692 out of 1000\n",
      "693 out of 1000\n",
      "694 out of 1000\n",
      "695 out of 1000\n",
      "696 out of 1000\n",
      "697 out of 1000\n",
      "698 out of 1000\n",
      "699 out of 1000\n",
      "700 out of 1000\n",
      "701 out of 1000\n",
      "702 out of 1000\n",
      "703 out of 1000\n",
      "704 out of 1000\n",
      "705 out of 1000\n",
      "706 out of 1000\n",
      "707 out of 1000\n",
      "708 out of 1000\n",
      "709 out of 1000\n",
      "710 out of 1000\n",
      "711 out of 1000\n",
      "712 out of 1000\n",
      "713 out of 1000\n",
      "714 out of 1000\n",
      "715 out of 1000\n",
      "716 out of 1000\n",
      "717 out of 1000\n",
      "718 out of 1000\n",
      "719 out of 1000\n",
      "720 out of 1000\n",
      "721 out of 1000\n",
      "722 out of 1000\n",
      "723 out of 1000\n",
      "724 out of 1000\n",
      "725 out of 1000\n",
      "726 out of 1000\n",
      "727 out of 1000\n",
      "728 out of 1000\n",
      "729 out of 1000\n",
      "730 out of 1000\n",
      "731 out of 1000\n",
      "732 out of 1000\n",
      "733 out of 1000\n",
      "734 out of 1000\n",
      "735 out of 1000\n",
      "736 out of 1000\n",
      "737 out of 1000\n",
      "738 out of 1000\n",
      "739 out of 1000\n",
      "740 out of 1000\n",
      "741 out of 1000\n",
      "742 out of 1000\n",
      "743 out of 1000\n",
      "744 out of 1000\n",
      "745 out of 1000\n",
      "746 out of 1000\n",
      "747 out of 1000\n",
      "748 out of 1000\n",
      "749 out of 1000\n",
      "750 out of 1000\n",
      "751 out of 1000\n",
      "752 out of 1000\n",
      "753 out of 1000\n",
      "754 out of 1000\n",
      "755 out of 1000\n",
      "756 out of 1000\n",
      "757 out of 1000\n",
      "758 out of 1000\n",
      "759 out of 1000\n",
      "760 out of 1000\n",
      "761 out of 1000\n",
      "762 out of 1000\n",
      "763 out of 1000\n",
      "764 out of 1000\n",
      "765 out of 1000\n",
      "766 out of 1000\n",
      "767 out of 1000\n",
      "768 out of 1000\n",
      "769 out of 1000\n",
      "770 out of 1000\n",
      "771 out of 1000\n",
      "772 out of 1000\n",
      "773 out of 1000\n",
      "774 out of 1000\n",
      "775 out of 1000\n",
      "776 out of 1000\n",
      "777 out of 1000\n",
      "778 out of 1000\n",
      "779 out of 1000\n",
      "780 out of 1000\n",
      "781 out of 1000\n",
      "782 out of 1000\n",
      "783 out of 1000\n",
      "784 out of 1000\n",
      "785 out of 1000\n",
      "786 out of 1000\n",
      "787 out of 1000\n",
      "788 out of 1000\n",
      "789 out of 1000\n",
      "790 out of 1000\n",
      "791 out of 1000\n",
      "792 out of 1000\n",
      "793 out of 1000\n",
      "794 out of 1000\n",
      "795 out of 1000\n",
      "796 out of 1000\n",
      "797 out of 1000\n",
      "798 out of 1000\n",
      "799 out of 1000\n",
      "800 out of 1000\n",
      "801 out of 1000\n",
      "802 out of 1000\n",
      "803 out of 1000\n",
      "804 out of 1000\n",
      "805 out of 1000\n",
      "806 out of 1000\n",
      "807 out of 1000\n",
      "808 out of 1000\n",
      "809 out of 1000\n",
      "810 out of 1000\n",
      "811 out of 1000\n",
      "812 out of 1000\n",
      "813 out of 1000\n",
      "814 out of 1000\n",
      "815 out of 1000\n",
      "816 out of 1000\n",
      "817 out of 1000\n",
      "818 out of 1000\n",
      "819 out of 1000\n",
      "820 out of 1000\n",
      "821 out of 1000\n",
      "822 out of 1000\n",
      "823 out of 1000\n",
      "824 out of 1000\n",
      "825 out of 1000\n",
      "826 out of 1000\n",
      "827 out of 1000\n",
      "828 out of 1000\n",
      "829 out of 1000\n",
      "830 out of 1000\n",
      "831 out of 1000\n",
      "832 out of 1000\n",
      "833 out of 1000\n",
      "834 out of 1000\n",
      "835 out of 1000\n",
      "836 out of 1000\n",
      "837 out of 1000\n",
      "838 out of 1000\n",
      "839 out of 1000\n",
      "840 out of 1000\n",
      "841 out of 1000\n",
      "842 out of 1000\n",
      "843 out of 1000\n",
      "844 out of 1000\n",
      "845 out of 1000\n",
      "846 out of 1000\n",
      "847 out of 1000\n",
      "848 out of 1000\n",
      "849 out of 1000\n",
      "850 out of 1000\n",
      "851 out of 1000\n",
      "852 out of 1000\n",
      "853 out of 1000\n",
      "854 out of 1000\n",
      "855 out of 1000\n",
      "856 out of 1000\n",
      "857 out of 1000\n",
      "858 out of 1000\n",
      "859 out of 1000\n",
      "860 out of 1000\n",
      "861 out of 1000\n",
      "862 out of 1000\n",
      "863 out of 1000\n",
      "864 out of 1000\n",
      "865 out of 1000\n",
      "866 out of 1000\n",
      "867 out of 1000\n",
      "868 out of 1000\n",
      "869 out of 1000\n",
      "870 out of 1000\n",
      "871 out of 1000\n",
      "872 out of 1000\n",
      "873 out of 1000\n",
      "874 out of 1000\n",
      "875 out of 1000\n",
      "876 out of 1000\n",
      "877 out of 1000\n",
      "878 out of 1000\n",
      "879 out of 1000\n",
      "880 out of 1000\n",
      "881 out of 1000\n",
      "882 out of 1000\n",
      "883 out of 1000\n",
      "884 out of 1000\n",
      "885 out of 1000\n",
      "886 out of 1000\n",
      "887 out of 1000\n",
      "888 out of 1000\n",
      "889 out of 1000\n",
      "890 out of 1000\n",
      "891 out of 1000\n",
      "892 out of 1000\n",
      "893 out of 1000\n",
      "894 out of 1000\n",
      "895 out of 1000\n",
      "896 out of 1000\n",
      "897 out of 1000\n",
      "898 out of 1000\n",
      "899 out of 1000\n",
      "900 out of 1000\n",
      "901 out of 1000\n",
      "902 out of 1000\n",
      "903 out of 1000\n",
      "904 out of 1000\n",
      "905 out of 1000\n",
      "906 out of 1000\n",
      "907 out of 1000\n",
      "908 out of 1000\n",
      "909 out of 1000\n",
      "910 out of 1000\n",
      "911 out of 1000\n",
      "912 out of 1000\n",
      "913 out of 1000\n",
      "914 out of 1000\n",
      "915 out of 1000\n",
      "916 out of 1000\n",
      "917 out of 1000\n",
      "918 out of 1000\n",
      "919 out of 1000\n",
      "920 out of 1000\n",
      "921 out of 1000\n",
      "922 out of 1000\n",
      "923 out of 1000\n",
      "924 out of 1000\n",
      "925 out of 1000\n",
      "926 out of 1000\n",
      "927 out of 1000\n",
      "928 out of 1000\n",
      "929 out of 1000\n",
      "930 out of 1000\n",
      "931 out of 1000\n",
      "932 out of 1000\n",
      "933 out of 1000\n",
      "934 out of 1000\n",
      "935 out of 1000\n",
      "936 out of 1000\n",
      "937 out of 1000\n",
      "938 out of 1000\n",
      "939 out of 1000\n",
      "940 out of 1000\n",
      "941 out of 1000\n",
      "942 out of 1000\n",
      "943 out of 1000\n",
      "944 out of 1000\n",
      "945 out of 1000\n",
      "946 out of 1000\n",
      "947 out of 1000\n",
      "948 out of 1000\n",
      "949 out of 1000\n",
      "950 out of 1000\n",
      "951 out of 1000\n",
      "952 out of 1000\n",
      "953 out of 1000\n",
      "954 out of 1000\n",
      "955 out of 1000\n",
      "956 out of 1000\n",
      "957 out of 1000\n",
      "958 out of 1000\n",
      "959 out of 1000\n",
      "960 out of 1000\n",
      "961 out of 1000\n",
      "962 out of 1000\n",
      "963 out of 1000\n",
      "964 out of 1000\n",
      "965 out of 1000\n",
      "966 out of 1000\n",
      "967 out of 1000\n",
      "968 out of 1000\n",
      "969 out of 1000\n",
      "970 out of 1000\n",
      "971 out of 1000\n",
      "972 out of 1000\n",
      "973 out of 1000\n",
      "974 out of 1000\n",
      "975 out of 1000\n",
      "976 out of 1000\n",
      "977 out of 1000\n",
      "978 out of 1000\n",
      "979 out of 1000\n",
      "980 out of 1000\n",
      "981 out of 1000\n",
      "982 out of 1000\n",
      "983 out of 1000\n",
      "984 out of 1000\n",
      "985 out of 1000\n",
      "986 out of 1000\n",
      "987 out of 1000\n",
      "988 out of 1000\n",
      "989 out of 1000\n",
      "990 out of 1000\n",
      "991 out of 1000\n",
      "992 out of 1000\n",
      "993 out of 1000\n",
      "994 out of 1000\n",
      "995 out of 1000\n",
      "996 out of 1000\n",
      "997 out of 1000\n",
      "998 out of 1000\n",
      "999 out of 1000\n",
      "1000 out of 1000\n",
      "<ipython-input-7-295fb99d2539>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokenized'] = tokenized\n",
      "<ipython-input-7-295fb99d2539>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tagged'] = tagged\n",
      "<ipython-input-7-295fb99d2539>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lower_tagged'] = lower_tagged\n"
     ]
    }
   ],
   "source": [
    "df = process_reviews(df[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     listing_id         id        date  reviewer_id     reviewer_name  \\\n",
       "0          2818       1191  2009-03-30        10952               Lam   \n",
       "1          2818       1771  2009-04-24        12798             Alice   \n",
       "2          2818       1989  2009-05-03        11869           Natalja   \n",
       "3          2818       2797  2009-05-18        14064           Enrique   \n",
       "4          2818       3151  2009-05-25        17977           Sherwin   \n",
       "..          ...        ...         ...          ...               ...   \n",
       "995       28871  257474270  2018-04-26     19146357              PPep   \n",
       "996       28871  258531725  2018-04-29     46895354             James   \n",
       "997       28871  259622953  2018-05-01     25353493             Brian   \n",
       "998       28871  261853402  2018-05-07    181166673  Manuel Alejandro   \n",
       "999       28871  262860515  2018-05-10    153766264            Dallas   \n",
       "\n",
       "                                              comments  \\\n",
       "0    Daniel is really cool. The place was nice and ...   \n",
       "1    Daniel is the most amazing host! His place is ...   \n",
       "2    We had such a great time in Amsterdam. Daniel ...   \n",
       "3    Very professional operation. Room is very clea...   \n",
       "4    Daniel is highly recommended.  He provided all...   \n",
       "..                                                 ...   \n",
       "995  Highly recommend , Nice place , Near everythin...   \n",
       "996  Edwin's place was fantastic for my wife's and ...   \n",
       "997  Our stay at Edwin’s was incredible. He is such...   \n",
       "998  Edwin is such a kind host, he is aware of you ...   \n",
       "999  Edwin is a great host. He made sure we were co...   \n",
       "\n",
       "                                             tokenized  \\\n",
       "0    [Daniel, is, really, cool, ., The, place, was,...   \n",
       "1    [Daniel, is, the, most, amazing, host, !, His,...   \n",
       "2    [We, had, such, a, great, time, in, Amsterdam,...   \n",
       "3    [Very, professional, operation, ., Room, is, v...   \n",
       "4    [Daniel, is, highly, recommended, ., He, provi...   \n",
       "..                                                 ...   \n",
       "995  [Highly, recommend, ,, Nice, place, ,, Near, e...   \n",
       "996  [Edwin, 's, place, was, fantastic, for, my, wi...   \n",
       "997  [Our, stay, at, Edwin, ’, s, was, incredible, ...   \n",
       "998  [Edwin, is, such, a, kind, host, ,, he, is, aw...   \n",
       "999  [Edwin, is, a, great, host, ., He, made, sure,...   \n",
       "\n",
       "                                                tagged  \\\n",
       "0    [(Daniel, NNP), (is, VBZ), (really, RB), (cool...   \n",
       "1    [(Daniel, NNP), (is, VBZ), (the, DT), (most, R...   \n",
       "2    [(We, PRP), (had, VBD), (such, JJ), (a, DT), (...   \n",
       "3    [(Very, RB), (professional, JJ), (operation, N...   \n",
       "4    [(Daniel, NNP), (is, VBZ), (highly, RB), (reco...   \n",
       "..                                                 ...   \n",
       "995  [(Highly, NNP), (recommend, NN), (,, ,), (Nice...   \n",
       "996  [(Edwin, NNP), ('s, POS), (place, NN), (was, V...   \n",
       "997  [(Our, PRP$), (stay, NN), (at, IN), (Edwin, NN...   \n",
       "998  [(Edwin, NNP), (is, VBZ), (such, JJ), (a, DT),...   \n",
       "999  [(Edwin, NNP), (is, VBZ), (a, DT), (great, JJ)...   \n",
       "\n",
       "                                          lower_tagged  \n",
       "0    [(in, IN), (didnt, VBP), (any, DT), (clean, JJ...  \n",
       "1    [(please, VBP), (way, NN), (bed, NN), (if, IN)...  \n",
       "2    [(bathroom, NN), (10-15, JJ), (in, IN), (we, P...  \n",
       "3    [(which, WDT), (clean, JJ), (comfortable, JJ),...  \n",
       "4    [(way, NN), (in, IN), (which, WDT), (recommend...  \n",
       "..                                                 ...  \n",
       "995  [(near, IN), (time, NN), (,, ,), (see, VBP), (...  \n",
       "996  [(bathroom, NN), (thank, NN), (in, IN), (being...  \n",
       "997  [(everywhere, RB), (s, NN), (accommodating, VB...  \n",
       "998  [(in, IN), (comfortable, JJ), (of, IN), (a, DT...  \n",
       "999  [(in, IN), (we, PRP), (distance, NN), (walkabl...  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>listing_id</th>\n      <th>id</th>\n      <th>date</th>\n      <th>reviewer_id</th>\n      <th>reviewer_name</th>\n      <th>comments</th>\n      <th>tokenized</th>\n      <th>tagged</th>\n      <th>lower_tagged</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2818</td>\n      <td>1191</td>\n      <td>2009-03-30</td>\n      <td>10952</td>\n      <td>Lam</td>\n      <td>Daniel is really cool. The place was nice and ...</td>\n      <td>[Daniel, is, really, cool, ., The, place, was,...</td>\n      <td>[(Daniel, NNP), (is, VBZ), (really, RB), (cool...</td>\n      <td>[(in, IN), (didnt, VBP), (any, DT), (clean, JJ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2818</td>\n      <td>1771</td>\n      <td>2009-04-24</td>\n      <td>12798</td>\n      <td>Alice</td>\n      <td>Daniel is the most amazing host! His place is ...</td>\n      <td>[Daniel, is, the, most, amazing, host, !, His,...</td>\n      <td>[(Daniel, NNP), (is, VBZ), (the, DT), (most, R...</td>\n      <td>[(please, VBP), (way, NN), (bed, NN), (if, IN)...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2818</td>\n      <td>1989</td>\n      <td>2009-05-03</td>\n      <td>11869</td>\n      <td>Natalja</td>\n      <td>We had such a great time in Amsterdam. Daniel ...</td>\n      <td>[We, had, such, a, great, time, in, Amsterdam,...</td>\n      <td>[(We, PRP), (had, VBD), (such, JJ), (a, DT), (...</td>\n      <td>[(bathroom, NN), (10-15, JJ), (in, IN), (we, P...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2818</td>\n      <td>2797</td>\n      <td>2009-05-18</td>\n      <td>14064</td>\n      <td>Enrique</td>\n      <td>Very professional operation. Room is very clea...</td>\n      <td>[Very, professional, operation, ., Room, is, v...</td>\n      <td>[(Very, RB), (professional, JJ), (operation, N...</td>\n      <td>[(which, WDT), (clean, JJ), (comfortable, JJ),...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2818</td>\n      <td>3151</td>\n      <td>2009-05-25</td>\n      <td>17977</td>\n      <td>Sherwin</td>\n      <td>Daniel is highly recommended.  He provided all...</td>\n      <td>[Daniel, is, highly, recommended, ., He, provi...</td>\n      <td>[(Daniel, NNP), (is, VBZ), (highly, RB), (reco...</td>\n      <td>[(way, NN), (in, IN), (which, WDT), (recommend...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>28871</td>\n      <td>257474270</td>\n      <td>2018-04-26</td>\n      <td>19146357</td>\n      <td>PPep</td>\n      <td>Highly recommend , Nice place , Near everythin...</td>\n      <td>[Highly, recommend, ,, Nice, place, ,, Near, e...</td>\n      <td>[(Highly, NNP), (recommend, NN), (,, ,), (Nice...</td>\n      <td>[(near, IN), (time, NN), (,, ,), (see, VBP), (...</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>28871</td>\n      <td>258531725</td>\n      <td>2018-04-29</td>\n      <td>46895354</td>\n      <td>James</td>\n      <td>Edwin's place was fantastic for my wife's and ...</td>\n      <td>[Edwin, 's, place, was, fantastic, for, my, wi...</td>\n      <td>[(Edwin, NNP), ('s, POS), (place, NN), (was, V...</td>\n      <td>[(bathroom, NN), (thank, NN), (in, IN), (being...</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>28871</td>\n      <td>259622953</td>\n      <td>2018-05-01</td>\n      <td>25353493</td>\n      <td>Brian</td>\n      <td>Our stay at Edwin’s was incredible. He is such...</td>\n      <td>[Our, stay, at, Edwin, ’, s, was, incredible, ...</td>\n      <td>[(Our, PRP$), (stay, NN), (at, IN), (Edwin, NN...</td>\n      <td>[(everywhere, RB), (s, NN), (accommodating, VB...</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>28871</td>\n      <td>261853402</td>\n      <td>2018-05-07</td>\n      <td>181166673</td>\n      <td>Manuel Alejandro</td>\n      <td>Edwin is such a kind host, he is aware of you ...</td>\n      <td>[Edwin, is, such, a, kind, host, ,, he, is, aw...</td>\n      <td>[(Edwin, NNP), (is, VBZ), (such, JJ), (a, DT),...</td>\n      <td>[(in, IN), (comfortable, JJ), (of, IN), (a, DT...</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>28871</td>\n      <td>262860515</td>\n      <td>2018-05-10</td>\n      <td>153766264</td>\n      <td>Dallas</td>\n      <td>Edwin is a great host. He made sure we were co...</td>\n      <td>[Edwin, is, a, great, host, ., He, made, sure,...</td>\n      <td>[(Edwin, NNP), (is, VBZ), (a, DT), (great, JJ)...</td>\n      <td>[(in, IN), (we, PRP), (distance, NN), (walkabl...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = 0\n",
    "# print(len(df.tagged[num]), len(set(df.lower_tagged[num])))\n",
    "# list(set(df.lower_tagged[num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'V'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df.lower_tagged[0][1][1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUaH-yNlQRL9"
   },
   "source": [
    "### 3.a2 - Create a vocabulary\n",
    "\n",
    "What to implement: A function `get_vocab(df)` which takes as input the DataFrame generated in step 1.c, and returns two lists, one for the 1,000 most frequent center words (nouns) and one for the 1,000 most frequent context words (either verbs or adjectives). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "sAg6VRwdQQmg"
   },
   "outputs": [],
   "source": [
    "def get_vocab(df):\n",
    "  cent_list, cont_list = [], []\n",
    "\n",
    "  for review in df.lower_tagged:\n",
    "    cent_list.extend([word for word in [list_of_words[0] for list_of_words in review if list_of_words[1][0] == 'N']])\n",
    "    cont_list.extend([word for word in [list_of_words[0] for list_of_words in review if (list_of_words[1][0] == 'J') or (list_of_words[1][0] == 'V')]])\n",
    "    \n",
    "  cent_dict = Counter(cent_list)\n",
    "  cont_dict = Counter(cont_list)\n",
    "\n",
    "  cent_vocab = [key for key, value in sorted(cent_dict.items(), key=lambda item: item[1])][:1000]\n",
    "  cont_vocab = [key for key, value in sorted(cont_dict.items(), key=lambda item: item[1])][:1000]\n",
    "\n",
    "  return cent_vocab, cont_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "F_R5l4IVSk9-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cent_vocab, cont_vocab = get_vocab(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'planet'"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "cent_vocab[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkqRGdQ_RUMg"
   },
   "source": [
    "### 3.a3 Count co-occurrences between center and context words\n",
    "\n",
    "What to implement: A function `get_coocs(df, center_vocab, context_vocab)` which takes as input the DataFrame generated in step 1, and the lists generated in step 2 and returns a dictionary of dictionaries, of the form in the example above. It is up to you how you define context (full review? per sentence? a sliding window of fixed size?), and how to deal with exceptional cases (center words occurring more than once, center and context words being part of your vocabulary because they are frequent both as a noun and as a verb, etc). Use comments in your code to justify your approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "comments = df.comments\n",
    "type(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    Daniel is really cool. The place was nice and ...\n",
       "1    Daniel is the most amazing host! His place is ...\n",
       "2    We had such a great time in Amsterdam. Daniel ...\n",
       "3    Very professional operation. Room is very clea...\n",
       "4    Daniel is highly recommended.  He provided all...\n",
       "Name: comments, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "comments[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "ddnfCbQWRd5R"
   },
   "outputs": [],
   "source": [
    "def get_coocs(df, cent_vocab, cont_vocab):\n",
    "  sentences = []\n",
    "  comments = df.comments\n",
    "\n",
    "  for comment in comments:\n",
    "    sentences.extend([sentence for sentence in comment.split('.')])\n",
    "  \n",
    "  # print(sentences)\n",
    "  \n",
    "  coocs = {}\n",
    "\n",
    "  for center_word in cent_vocab:\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "      if center_word in sentence:\n",
    "        words_in_sentence = word_tokenize(sentence)\n",
    "        words.extend([word for word in words_in_sentence if word in cont_vocab])\n",
    "    \n",
    "    center_word_dict = dict(Counter(words))\n",
    "    coocs[center_word] = center_word_dict\n",
    "    \n",
    "  # cent_dict = Counter(cent_list)\n",
    "  # cont_dict = Counter(cont_list)\n",
    "  \n",
    "  return coocs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "iTT_TOkaSoXL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "coocs = get_coocs(df, cent_vocab, cont_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "coocs['planet']['lonely']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be6mOXqMRlt-"
   },
   "source": [
    "### 3.a4 Convert co-occurrence dictionary to 1000x1000 dataframe\n",
    "What to implement: A function called `cooc_dict2df(cooc_dict)`, which takes as input the dictionary of dictionaries generated in step 3 and returns a DataFrame where each row corresponds to one center word, and each column corresponds to one context word, and cells are their corresponding co-occurrence value. Some (x,y) pairs will never co-occur, you should have a 0 value for those cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "C6WuM5U7RsBJ"
   },
   "outputs": [],
   "source": [
    "def cooc_dict2df(coocs):\n",
    "  coocdf = pd.DataFrame(columns=cont_vocab, index = cent_vocab)\n",
    "\n",
    "  for index, row in coocdf.iterrows():\n",
    "    for word in cont_vocab:\n",
    "      try:\n",
    "        coocdf[word][index] = coocs[index][word]\n",
    "      except: \n",
    "        coocdf[word][index] = 0\n",
    "\n",
    "  return coocdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "cwAflxldSrbg"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "coocdf = cooc_dict2df(coocs)\n",
    "coocdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EWllWryR-QL"
   },
   "source": [
    "### 3.a5 Raw co-occurrences to PMI scores\n",
    "\n",
    "What to implement: A function `cooc2pmi(df)` that takes as input the DataFrame generated in step 4, and returns a new DataFrame with the same rows and columns, but with PMI scores instead of raw co-occurrence counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frTTs7-eSFHv"
   },
   "outputs": [],
   "source": [
    "def cooc2pmi(df):\n",
    "  # your code here\n",
    "  return pmidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGftXjXRSuQw"
   },
   "outputs": [],
   "source": [
    "pmidf = cooc2pmi(coocdf)\n",
    "pmidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaLRvjRySOYB"
   },
   "source": [
    "### 3.a6 Retrieve top-k context words, given a center word\n",
    "\n",
    "What to implement: A function `topk(df, center_word, N=10)` that takes as input: (1) the DataFrame generated in step 5, (2) a `center_word` (a string like `‘towels’`), and (3) an optional named argument called `N` with default value of 10; and returns a list of `N` strings, in order of their PMI score with the `center_word`. You do not need to handle cases for which the word `center_word` is not found in `df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlKUP9SgSXlL"
   },
   "outputs": [],
   "source": [
    "def topk(df, center_word, N=10):\n",
    "  # your code here\n",
    "  return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1I038zG1Sw62"
   },
   "outputs": [],
   "source": [
    "topk(pmidf, 'coffee')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hfcm5-7b0HKO"
   },
   "source": [
    "# 3.b Ethical, social and legal implications\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qd3uf-Qq4tYg"
   },
   "source": [
    "Local authorities in touristic hotspots like Amsterdam, NYC or Barcelona regulate the price of recreational apartments for rent to, among others, ensure that fair rent prices are kept for year-long residents. Consider your price recommender for hosts in Question 2c. Imagine that Airbnb recommends a new host to put the price of your flat at a price which is above the official regulations established by the local government. Upon inspection, you realize that the inflated price you have been recommended comes from many apartments in the area only being offered during an annual event which brings many tourists, and which causes prices to rise. \n",
    "\n",
    "In this context, critically reflect on the compliance of this recommender system with **one of the five actions** outlined in the **UK’s Data Ethics Framework**. You should prioritize the action that, in your opinion, is the weakest. Then, justify your choice by critically analyzing the three **key principles** outlined in the Framework, namely _transparency_, _accountability_ and _fairness_. Finally, you should propose and critically justify a solution that would improve the recommender system in at least one of these principles. You are strongly encouraged to follow a scholarly approach, e.g., with peer-reviewed references as support. \n",
    "\n",
    "Your report should be between 500 and 750 words long.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6QJyuP6I1Ht"
   },
   "source": [
    "### Your answer here. No Python, only Markdown.\n",
    "\n",
    "Write your answer after the line.\n",
    "\n",
    "---\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part 3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python395jvsc74a57bd03f75a622fdbe68ac4774c6ea619d86cc770141a8bef94a85fce2870eb7cb09bf",
   "display_name": "Python 3.9.5 64-bit ('Python39')"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "3f75a622fdbe68ac4774c6ea619d86cc770141a8bef94a85fce2870eb7cb09bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}